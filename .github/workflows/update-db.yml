# .github/workflows/update-db.yml
name: Update StellCoilBench Database

on:
  push:
    branches: [ main ]

jobs:
  determine-cases:
    runs-on: ubuntu-24.04
    outputs:
      cases_to_run: ${{ steps.filter.outputs.cases_to_run }}
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"

      - name: Fetch latest submissions from main
        run: |
          git fetch origin main || echo "Fetch failed (non-critical, will check local state)"
          if git rev-parse --verify origin/main > /dev/null 2>&1; then
            BEHIND_COUNT=$(git rev-list origin/main ^HEAD 2>/dev/null | wc -l || echo "0")
            if [ "$BEHIND_COUNT" -gt 0 ]; then
              echo "Merging origin/main to include submissions from previous runs..."
              git merge origin/main --no-edit --no-ff || {
                CONFLICTS=$(git diff --name-only --diff-filter=U 2>/dev/null || true)
                if [ -n "$CONFLICTS" ]; then
                  echo "$CONFLICTS" | grep "^docs/" | while read file; do
                    [ -n "$file" ] && git checkout --theirs "$file" 2>/dev/null && git add "$file" 2>/dev/null || true
                  done
                  echo "$CONFLICTS" | grep "^submissions/" | while read file; do
                    [ -n "$file" ] && git checkout --theirs "$file" 2>/dev/null && git add "$file" 2>/dev/null || true
                  done
                  git commit --no-edit || echo "Merge commit failed"
                else
                  git merge --abort 2>/dev/null || true
                fi
              }
            fi
          fi

      - name: Filter cases to run
        id: filter
        run: |
          ALL_CASE_FILES=$(find cases -name "*.yaml" -type f | sort)
          
          if [ -z "$ALL_CASE_FILES" ]; then
            echo "ERROR: No .yaml files found in cases/ directory!"
            exit 1
          fi
          
          TEMP_CASES=$(mktemp)
          echo "$ALL_CASE_FILES" > "$TEMP_CASES"
          
          PYTHON_OUTPUT=$(python3 - "$TEMP_CASES" << 'PYTHON_SCRIPT'
          import sys
          import yaml
          import zipfile
          from pathlib import Path
          import json
          
          def normalize_yaml_content(content):
              try:
                  data = yaml.safe_load(content)
                  return yaml.dump(data, sort_keys=True, default_flow_style=False)
              except:
                  return content
          
          def case_has_successful_submission(case_file_path):
              case_path = Path(case_file_path)
              if not case_path.exists():
                  return False
              
              try:
                  current_case_content = case_path.read_text()
                  current_case_normalized = normalize_yaml_content(current_case_content)
              except Exception as e:
                  print(f"Warning: Failed to read case file {case_file_path}: {e}", file=sys.stderr)
                  return False
              
              try:
                  repo_root = Path.cwd()
                  case_file_rel = str(case_path.resolve().relative_to(repo_root.resolve()))
              except ValueError:
                  case_file_rel = str(case_path.resolve())
              
              case_file_rel_normalized = case_file_rel.replace("\\", "/")
              
              submissions_dir = Path("submissions")
              if not submissions_dir.exists():
                  return False
              
              zip_files = list(submissions_dir.rglob("*.zip"))
              if len(zip_files) == 0:
                  return False
              
              for zip_path in zip_files:
                  try:
                      with zipfile.ZipFile(zip_path, 'r') as zf:
                          if 'case.yaml' not in zf.namelist() or 'results.json' not in zf.namelist():
                              continue
                          
                          zip_case_content = zf.read('case.yaml').decode('utf-8')
                          zip_case_data = yaml.safe_load(zip_case_content)
                          
                          submission_source = zip_case_data.get('source_case_file', '')
                          if submission_source:
                              submission_source_normalized = submission_source.replace("\\", "/")
                              if (submission_source == case_file_rel or 
                                  submission_source_normalized == case_file_rel_normalized):
                                  zip_case_data_for_comparison = {k: v for k, v in zip_case_data.items() if k != 'source_case_file'}
                                  zip_case_normalized = yaml.dump(zip_case_data_for_comparison, sort_keys=True, default_flow_style=False)
                                  
                                  if zip_case_normalized == current_case_normalized:
                                      return True
                  except Exception as e:
                      print(f"Warning: Failed to process {zip_path}: {e}", file=sys.stderr)
                      continue
              
              return False
          
          if len(sys.argv) > 1:
              with open(sys.argv[1], 'r') as f:
                  case_files = [line.strip() for line in f if line.strip()]
          else:
              case_files = [line.strip() for line in sys.stdin if line.strip()]
          
          if not case_files:
              print("ERROR: No case files found!", file=sys.stderr)
              sys.exit(1)
          
          cases_to_run = []
          cases_already_successful = []
          
          for case_file in case_files:
              if case_has_successful_submission(case_file):
                  cases_already_successful.append(case_file)
                  print(f"SKIP: {case_file} (has successful submission)", file=sys.stderr)
              else:
                  cases_to_run.append(case_file)
                  print(f"RUN: {case_file} (new or no successful submission)", file=sys.stderr)
          
          result = {
              "to_run": cases_to_run,
              "already_successful": cases_already_successful
          }
          print(json.dumps(result))
          PYTHON_SCRIPT
          )
          
          rm -f "$TEMP_CASES"
          
          CASES_TO_RUN_JSON=$(echo "$PYTHON_OUTPUT" | python3 -c "import sys, json; data = json.load(sys.stdin); print(json.dumps(data['to_run']))")
          
          echo "cases_to_run_json<<EOF" >> $GITHUB_OUTPUT
          echo "$CASES_TO_RUN_JSON" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          CASES_TO_RUN=$(echo "$PYTHON_OUTPUT" | python3 -c "import sys, json; data = json.load(sys.stdin); print(' '.join(data['to_run']))")
          echo "Cases to run: $CASES_TO_RUN"

  run-cases:
    needs: determine-cases
    if: needs.determine-cases.outputs.cases_to_run_json != '[]'
    runs-on: ubuntu-24.04
    permissions:
      contents: write
    strategy:
      fail-fast: false
      matrix:
        case_file: ${{ fromJson(needs.determine-cases.outputs.cases_to_run_json) }}
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}
      - name: apt-get stuff needed for vmec
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential gfortran openmpi-bin libopenmpi-dev libnetcdf-dev libnetcdff-dev liblapack-dev libscalapack-mpi-dev libhdf5-dev libhdf5-serial-dev git m4 libfftw3-dev libboost-all-dev libopenblas-dev

      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Fetch all history for proper branch operations
          token: ${{ secrets.GITHUB_TOKEN }}  # Explicit token for write access

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"
  
      - name: which pip after python setup
        run: |
          python -m pip install --upgrade pip
          pip --version
  
      - name: env after adding python
        run: env

      - name: Download the VMEC2000 standalone repository
        run: git clone --depth=1 https://github.com/hiddensymmetries/VMEC2000.git
  
      - name: Install python dependencies
        run: |
          sudo apt-get install -y graphviz graphviz-dev
          pip install numpy cmake scikit-build f90nml ninja wheel setuptools pyevtk matplotlib mpi4py h5py f90wrap

      - name: Install booz_xform
        run: pip install -v git+https://github.com/hiddenSymmetries/booz_xform

      - name: ls in /usr/lib/x86_64-linux-gnu
        run: ls -l /usr/lib/x86_64-linux-gnu
  
      - name: Add to LD_LIBRARY_PATH so scalapack etc can be found
        run: echo "LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu" >> $GITHUB_ENV
  
      - name: env after adding to LD_LIBRARY_PATH
        run: env
  
      - name: ls in VMEC2000/python 1
        run: ls -l VMEC2000/python

      - name: Configure and install VMEC2000 module
        run: |
          cd VMEC2000
          cp cmake/machines/ubuntu.json cmake_config_file.json
          cat cmake_config_file.json
          pip install .

      - name: Try importing vmec module
        run: python -c "import vmec; print('VMEC module imported successfully')"

      - name: Install package
        run: |
          pip install -e .

      - name: Check if surface file exists
        run: |
          SURFACE_NAME=$(grep -A 2 "surface_params:" "${{ matrix.case_file }}" | grep "surface:" | awk '{print $2}' | tr -d '"')
          if [ -n "$SURFACE_NAME" ]; then
            if [ ! -f "plasma_surfaces/$SURFACE_NAME" ] && [ ! -f "plasma_surfaces/${SURFACE_NAME,,}" ]; then
              echo "ERROR: Surface file '$SURFACE_NAME' not found in plasma_surfaces/"
              exit 1
            fi
          fi

      - name: Run case file
        run: |
          echo "=========================================="
          echo "Running case: ${{ matrix.case_file }}"
          echo "(New case or previously failed - will retry until successful)"
          echo "=========================================="
          stellcoilbench submit-case "${{ matrix.case_file }}"

      - name: Configure Git
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "$GITHUB_ACTOR"

      - name: Commit submission
        run: |
          # Check if any submissions were generated
          if [ -n "$(find submissions -name "*.zip" -type f -newer /proc/self 2>/dev/null || find submissions -name "*.zip" -type f 2>/dev/null)" ]; then
            echo "Found new submission files, committing..."
            git add submissions/ || echo "git add failed"
            if ! git diff --staged --quiet; then
              git commit -m "chore: add CI-generated submission for ${{ matrix.case_file }}" || echo "Commit failed (may already be committed)"
              git push origin main || echo "Push failed (may already be pushed)"
            else
              echo "No new submissions to commit for this case"
            fi
          else
            echo "No new submissions generated for this case"
          fi

  commit-submissions:
    needs: run-cases
    if: always() && needs.run-cases.result != 'skipped'
    runs-on: ubuntu-24.04
    permissions:
      contents: write
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Configure Git
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "$GITHUB_ACTOR"

      - name: Wait for all matrix jobs and fetch submissions
        run: |
          echo "Waiting for all parallel case jobs to complete and commit their submissions..."
          echo "Fetching latest from origin/main to get all submissions from parallel jobs..."
          sleep 10  # Give matrix jobs time to commit
          git fetch origin main || echo "Fetch failed (non-critical)"
          
          # Merge to get all submissions from parallel jobs
          if git rev-parse --verify origin/main > /dev/null 2>&1; then
            BEHIND_COUNT=$(git rev-list origin/main ^HEAD 2>/dev/null | wc -l || echo "0")
            if [ "$BEHIND_COUNT" -gt 0 ]; then
              echo "Merging origin/main to include all submissions from parallel jobs..."
              git merge origin/main --no-edit --no-ff || {
                CONFLICTS=$(git diff --name-only --diff-filter=U 2>/dev/null || true)
                if [ -n "$CONFLICTS" ]; then
                  echo "$CONFLICTS" | grep "^submissions/" | while read file; do
                    [ -n "$file" ] && git checkout --theirs "$file" 2>/dev/null && git add "$file" 2>/dev/null || true
                  done
                  git commit --no-edit || echo "Merge commit failed"
                else
                  git merge --abort 2>/dev/null || true
                fi
              }
            fi
          fi
          
          echo "All submissions collected:"
          find submissions -name "*.zip" -type f | wc -l || echo "0"

  generate-leaderboard:
    needs: commit-submissions
    if: always() && needs.commit-submissions.result != 'skipped'
    runs-on: ubuntu-24.04
    permissions:
      contents: write
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"

      - name: Install package
        run: |
          pip install -e .

      - name: Configure Git
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "$GITHUB_ACTOR"

      - name: Generate and commit leaderboard files to main
        run: |
          # Ensure we're on main and have latest submissions
          echo "Current branch: $(git branch --show-current)"
          
          # Step 1 already committed submissions locally and pushed them
          # Fetch the latest to ensure we have Step 1's commits
          echo "Fetching latest from origin (including Step 1's commits)..."
          git fetch origin main || echo "Fetch failed (non-critical)"
          
          # Show what commits we have locally vs remote
          echo "Local commits:"
          git log --oneline -5 || echo "No local commits"
          echo "Remote commits:"
          git log --oneline origin/main -5 || echo "No remote commits"
          
          # Clean up any untracked files in docs/leaderboards/ that would conflict with merge
          # These are generated files that will be regenerated anyway - always remove them
          echo "Cleaning untracked files in docs/leaderboards/ that would conflict with merge..."
          # Aggressively remove all untracked files in docs/leaderboards/
          if [ -d "docs/leaderboards" ]; then
            # Remove all untracked .md files
            find docs/leaderboards -name "*.md" -type f ! -path "*/\.git/*" | while read file; do
              if ! git ls-files --error-unmatch "$file" >/dev/null 2>&1; then
                echo "Removing untracked file: $file"
                rm -f "$file"
              fi
            done
            # Also use git clean as fallback
            git clean -fd docs/leaderboards/ 2>/dev/null || true
          fi
          # Also remove untracked leaderboard.json if it exists
          if [ -f "docs/leaderboard.json" ] && ! git ls-files --error-unmatch docs/leaderboard.json >/dev/null 2>&1; then
            echo "Removing untracked file: docs/leaderboard.json"
            rm -f docs/leaderboard.json
          fi
          
          # Step 1 already committed and pushed submissions locally
          # We need to ensure we have those submissions before generating leaderboards
          # Check if we're ahead of origin/main (Step 1's commits)
          LOCAL_COMMITS=$(git rev-list HEAD ^origin/main 2>/dev/null | wc -l || echo "0")
          echo "Local commits ahead of origin/main: $LOCAL_COMMITS"
          
          # If we have local commits, we already have Step 1's submissions
          # Still fetch to get any other remote updates, but don't merge if it would conflict
          echo "Fetching latest from origin..."
          git fetch origin main || echo "Fetch failed (non-critical)"
          
          # Only merge if we're behind origin/main (to get submissions from previous runs)
          # But preserve local commits from Step 1
          if git rev-parse --verify origin/main > /dev/null 2>&1; then
            BEHIND_COUNT=$(git rev-list origin/main ^HEAD 2>/dev/null | wc -l || echo "0")
            if [ "$BEHIND_COUNT" -gt 0 ]; then
              echo "Merging origin/main to include submissions from previous runs..."
              git merge origin/main --no-edit --no-ff || {
                # If merge fails, resolve conflicts by keeping local submissions
                CONFLICTS=$(git diff --name-only --diff-filter=U 2>/dev/null || true)
                if [ -n "$CONFLICTS" ]; then
                  echo "$CONFLICTS" | grep "^submissions/" | while read file; do
                    [ -n "$file" ] && git checkout --ours "$file" 2>/dev/null && git add "$file" 2>/dev/null || true
                  done
                  echo "$CONFLICTS" | grep "^docs/" | while read file; do
                    [ -n "$file" ] && git checkout --theirs "$file" 2>/dev/null && git add "$file" 2>/dev/null || true
                  done
                  git commit --no-edit || echo "Merge commit failed"
                else
                  git merge --abort 2>/dev/null || true
                fi
              }
            else
              echo "Already up to date with origin/main, using local state"
            fi
          fi
          
          # Count submissions (should include both locally committed and merged from remote)
          # Submissions are now zipped
          SUBMISSIONS_COUNT=$(find submissions -name "*.zip" -type f 2>/dev/null | wc -l)
          echo "Submissions found: $SUBMISSIONS_COUNT"
          echo "All submission zip files:"
          find submissions -name "*.zip" -type f | sort || echo "No zip files found"
          
          # Generate leaderboard files (processes all submissions in submissions/ directory)
          # Remove old leaderboard files first to ensure clean regeneration
          echo "Removing old leaderboard files to ensure clean regeneration..."
          rm -f docs/leaderboard.json
          # Remove all existing leaderboard markdown files
          if [ -d "docs/leaderboards" ]; then
            find docs/leaderboards -name "*.md" -type f -delete
            echo "Removed old leaderboard .md files"
          fi
          
          echo "Generating leaderboard files..."
          echo "Running stellcoilbench update-db..."
          # Capture stderr output which contains diagnostics
          stellcoilbench update-db 2>&1 | tee /tmp/update-db-output.log
          echo ""
          echo "=== Update-db diagnostic summary ==="
          grep -E "(Loaded|skipped|filtered|Warning|Methods dict|Leaderboard:|Surface leaderboards|entries)" /tmp/update-db-output.log | head -20 || echo "No diagnostic output found"
          echo "===================================="
          
          # Verify all expected leaderboard files were generated
          echo "Verifying generated leaderboard files..."
          if [ -d "docs/leaderboards" ]; then
            echo "Generated leaderboard files:"
            ls -la docs/leaderboards/*.md 2>/dev/null || echo "No .md files found"
            
            # Check for specific surfaces
            for surface in rotating_ellipse LandremanPaul2021_QA circular_tokamak muse_focus; do
              if [ -f "docs/leaderboards/${surface}.md" ]; then
                echo "âœ“ ${surface}.md exists"
              else
                echo "WARNING: ${surface}.md not found"
              fi
            done
          fi
          
          # Verify files were generated
          echo "Checking generated files..."
          ls -la docs/ 2>/dev/null || echo "docs/ directory not found"
          ls -la docs/*.md 2>/dev/null | head -5 || echo "No markdown files in docs/"
          
          # Add generated leaderboard files
          # Note: docs/leaderboard.json is optional reference, methods.json and cases.json are not saved
          echo "Adding leaderboard files..."
          ADDED_ANY=false
          
          # Add individual files if they exist
          for file in docs/leaderboard.json; do
            if [ -f "$file" ]; then
              echo "Adding $file"
              git add "$file" && ADDED_ANY=true
            else
              echo "File not found: $file"
            fi
          done
          
          # Add leaderboard directories if they exist
          if [ -d "docs/leaderboards" ]; then
            echo "Adding all docs/leaderboards/*.md files"
            # Use find to ensure we get all .md files, including new ones
            find docs/leaderboards -name "*.md" -type f | while read file; do
              echo "  Adding: $file"
              git add "$file" && ADDED_ANY=true
            done
          fi
          
          # Remove old leaderboard file if it exists (singular .md file, replaced by docs/leaderboards/ directory)
          if [ -f "docs/leaderboard.md" ]; then
            echo "Removing old docs/leaderboard.md"
            git rm -f docs/leaderboard.md 2>/dev/null || true
          fi
          # Note: docs/leaderboards/ directory is now tracked, so we don't remove it
          # Files are added/updated explicitly above, and old files will be overwritten by new generation
          
          echo "Files added: $ADDED_ANY"
          
          # Show git status before committing
          echo "Git status before commit:"
          git status --short | head -20
          
          # Commit if there are changes
          if ! git diff --staged --quiet; then
            echo "Committing leaderboard files to main..."
            git commit -m "chore: update StellCoilBench leaderboard" || echo "Commit failed"
            echo "Pushing to main..."
            git push origin main || (echo "ERROR: Failed to push to main" && exit 1)
            echo "Successfully pushed leaderboard files to main"
          else
            echo "No leaderboard changes to commit"
            echo "Staged files:"
            git diff --staged --name-only || echo "No staged files"
            echo "Untracked/modified files:"
            git status --short | grep -E "(docs/|db/)" | head -10 || echo "No leaderboard files found"
          fi

      - name: Trigger ReadTheDocs build
        if: always()
        run: |
          # Trigger ReadTheDocs build via webhook API if credentials are available
          # This ensures docs build happens after CI runs complete and PDFs are committed
          if [ -n "${{ secrets.RTDS_WEBHOOK_URL }}" ] && [ -n "${{ secrets.RTDS_WEBHOOK_TOKEN }}" ]; then
            echo "Triggering ReadTheDocs build..."
            curl -X POST "${{ secrets.RTDS_WEBHOOK_URL }}" \
              -H "Authorization: token ${{ secrets.RTDS_WEBHOOK_TOKEN }}" \
              -H "Content-Type: application/json" \
              -d '{"branches": ["main"]}' || echo "Warning: Failed to trigger ReadTheDocs build (non-critical)"
          else
            echo "ReadTheDocs webhook credentials not configured - skipping build trigger"
            echo "To enable automatic docs builds after CI completes, add RTDS_WEBHOOK_URL and RTDS_WEBHOOK_TOKEN secrets"
            echo "See: https://docs.readthedocs.com/platform/stable/guides/build/webhooks.html"
          fi

