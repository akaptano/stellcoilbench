# .github/workflows/update-db.yml
name: Update StellCoilBench Database

on:
  push:
    branches: [ main ]

jobs:
  determine-cases:
    runs-on: ubuntu-24.04
    outputs:
      cases_to_run_json: ${{ steps.filter.outputs.cases_to_run_json }}
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pyyaml

      - name: Fetch latest submissions from main
        run: |
          git fetch origin main || echo "Fetch failed (non-critical, will check local state)"
          if git rev-parse --verify origin/main > /dev/null 2>&1; then
            BEHIND_COUNT=$(git rev-list origin/main ^HEAD 2>/dev/null | wc -l || echo "0")
            if [ "$BEHIND_COUNT" -gt 0 ]; then
              echo "Merging origin/main to include submissions from previous runs..."
              git merge origin/main --no-edit --no-ff || {
                CONFLICTS=$(git diff --name-only --diff-filter=U 2>/dev/null || true)
                if [ -n "$CONFLICTS" ]; then
                  echo "$CONFLICTS" | grep "^docs/" | while read file; do
                    [ -n "$file" ] && git checkout --theirs "$file" 2>/dev/null && git add "$file" 2>/dev/null || true
                  done
                  echo "$CONFLICTS" | grep "^submissions/" | while read file; do
                    [ -n "$file" ] && git checkout --theirs "$file" 2>/dev/null && git add "$file" 2>/dev/null || true
                  done
                  git commit --no-edit || echo "Merge commit failed"
                else
                  git merge --abort 2>/dev/null || true
                fi
              }
            fi
          fi

      - name: Filter cases to run
        id: filter
        run: |
          ALL_CASE_FILES=$(find cases -name "*.yaml" -type f | sort)
          
          if [ -z "$ALL_CASE_FILES" ]; then
            echo "ERROR: No .yaml files found in cases/ directory!"
            exit 1
          fi
          
          TEMP_CASES=$(mktemp)
          echo "$ALL_CASE_FILES" > "$TEMP_CASES"
          
          PYTHON_OUTPUT=$(python3 - "$TEMP_CASES" << 'PYTHON_SCRIPT'
          import sys
          import yaml
          import zipfile
          from pathlib import Path
          import json
          
          def normalize_yaml_content(content):
              try:
                  data = yaml.safe_load(content)
                  return yaml.dump(data, sort_keys=True, default_flow_style=False)
              except:
                  return content
          
          def case_has_successful_submission(case_file_path):
              case_path = Path(case_file_path)
              if not case_path.exists():
                  return False
              
              try:
                  current_case_content = case_path.read_text()
                  current_case_normalized = normalize_yaml_content(current_case_content)
              except Exception as e:
                  print(f"Warning: Failed to read case file {case_file_path}: {e}", file=sys.stderr)
                  return False
              
              try:
                  repo_root = Path.cwd()
                  case_file_rel = str(case_path.resolve().relative_to(repo_root.resolve()))
              except ValueError:
                  case_file_rel = str(case_path.resolve())
              
              case_file_rel_normalized = case_file_rel.replace("\\", "/")
              
              submissions_dir = Path("submissions")
              if not submissions_dir.exists():
                  return False
              
              # Check both committed (in git) and uncommitted (local) submissions
              # This handles cases where submissions were created but not yet committed
              zip_files = list(submissions_dir.rglob("*.zip"))
              if len(zip_files) == 0:
                  return False
              
              # Also check git for committed submissions (in case local files were cleaned up)
              import subprocess
              try:
                  git_ls_result = subprocess.run(
                      ["git", "ls-files", "submissions/**/*.zip"],
                      capture_output=True,
                      text=True,
                      timeout=10
                  )
                  if git_ls_result.returncode == 0 and git_ls_result.stdout.strip():
                      git_zip_files = [Path(f) for f in git_ls_result.stdout.strip().split("\n") if f]
                      # Add git-tracked files that exist locally
                      for git_zip in git_zip_files:
                          if git_zip.exists() and git_zip not in zip_files:
                              zip_files.append(git_zip)
              except Exception as e:
                  print(f"Warning: Could not check git for submissions: {e}", file=sys.stderr)
              
              for zip_path in zip_files:
                  try:
                      with zipfile.ZipFile(zip_path, 'r') as zf:
                          if 'case.yaml' not in zf.namelist() or 'results.json' not in zf.namelist():
                              continue
                          
                          zip_case_content = zf.read('case.yaml').decode('utf-8')
                          zip_case_data = yaml.safe_load(zip_case_content)
                          
                          submission_source = zip_case_data.get('source_case_file', '')
                          if submission_source:
                              submission_source_normalized = submission_source.replace("\\", "/")
                              if (submission_source == case_file_rel or 
                                  submission_source_normalized == case_file_rel_normalized):
                                  zip_case_data_for_comparison = {k: v for k, v in zip_case_data.items() if k != 'source_case_file'}
                                  zip_case_normalized = yaml.dump(zip_case_data_for_comparison, sort_keys=True, default_flow_style=False)
                                  
                                  if zip_case_normalized == current_case_normalized:
                                      return True
                  except Exception as e:
                      print(f"Warning: Failed to process {zip_path}: {e}", file=sys.stderr)
                      continue
              
              return False
          
          if len(sys.argv) > 1:
              with open(sys.argv[1], 'r') as f:
                  case_files = [line.strip() for line in f if line.strip()]
          else:
              case_files = [line.strip() for line in sys.stdin if line.strip()]
          
          if not case_files:
              print("ERROR: No case files found!", file=sys.stderr)
              sys.exit(1)
          
          cases_to_run = []
          cases_already_successful = []
          
          for case_file in case_files:
              if case_has_successful_submission(case_file):
                  cases_already_successful.append(case_file)
                  print(f"SKIP: {case_file} (has successful submission)", file=sys.stderr)
              else:
                  cases_to_run.append(case_file)
                  print(f"RUN: {case_file} (new or no successful submission)", file=sys.stderr)
          
          result = {
              "to_run": cases_to_run,
              "already_successful": cases_already_successful
          }
          print(json.dumps(result))
          PYTHON_SCRIPT
          )
          
          rm -f "$TEMP_CASES"
          
          CASES_TO_RUN_JSON=$(echo "$PYTHON_OUTPUT" | python3 -c "import sys, json; data = json.load(sys.stdin); print(json.dumps(data['to_run']))")
          
          echo "cases_to_run_json<<EOF" >> $GITHUB_OUTPUT
          echo "$CASES_TO_RUN_JSON" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          CASES_TO_RUN=$(echo "$PYTHON_OUTPUT" | python3 -c "import sys, json; data = json.load(sys.stdin); print(' '.join(data['to_run']))")
          echo "Cases to run: $CASES_TO_RUN"
          echo "Cases already successful: $(echo "$PYTHON_OUTPUT" | python3 -c "import sys, json; data = json.load(sys.stdin); print(' '.join(data['already_successful']))")"
          
          # Also output as a simple string for debugging
          echo "cases_to_run=$CASES_TO_RUN" >> $GITHUB_OUTPUT
          
          # Debug: Show what cases were found
          echo ""
          echo "=== Debug: Case filtering results ==="
          echo "$PYTHON_OUTPUT" | python3 -c "import sys, json; data = json.load(sys.stdin); print(f\"Total cases found: {len(data['to_run']) + len(data['already_successful'])}\"); print(f\"Cases to run: {len(data['to_run'])}\"); print(f\"Cases skipped: {len(data['already_successful'])}\")"

  run-cases:
    needs: [determine-cases]
    if: needs.determine-cases.outputs.cases_to_run_json != '[]'
    runs-on: ubuntu-24.04
    timeout-minutes: 360  # 6 hours - maximum allowed by GitHub Actions for GitHub-hosted runners
    permissions:
      contents: write
    strategy:
      fail-fast: false
      matrix:
        case_file: ${{ fromJson(needs.determine-cases.outputs.cases_to_run_json) }}
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Fetch all history for proper branch operations
          token: ${{ secrets.GITHUB_TOKEN }}  # Explicit token for write access

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"

      - name: apt-get stuff needed for vmec
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential gfortran openmpi-bin libopenmpi-dev libnetcdf-dev libnetcdff-dev liblapack-dev libscalapack-mpi-dev libhdf5-dev libhdf5-serial-dev git m4 libfftw3-dev libboost-all-dev libopenblas-dev graphviz graphviz-dev

      - name: Install python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install numpy cmake scikit-build f90nml ninja wheel setuptools pyevtk matplotlib mpi4py h5py f90wrap

      - name: Download the VMEC2000 standalone repository
        run: git clone --depth=1 https://github.com/hiddensymmetries/VMEC2000.git

      - name: Add to LD_LIBRARY_PATH so scalapack etc can be found
        run: echo "LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu" >> $GITHUB_ENV

      - name: Install booz_xform
        run: pip install -v git+https://github.com/hiddenSymmetries/booz_xform

      - name: Configure and install VMEC2000 module
        run: |
          cd VMEC2000
          cp cmake/machines/ubuntu.json cmake_config_file.json
          pip install .

      - name: Install package
        run: |
          pip install -e .

      - name: Check if surface file exists
        run: |
          SURFACE_NAME=$(grep -A 2 "surface_params:" "${{ matrix.case_file }}" | grep "surface:" | awk '{print $2}' | tr -d '"')
          if [ -n "$SURFACE_NAME" ]; then
            if [ ! -f "plasma_surfaces/$SURFACE_NAME" ] && [ ! -f "plasma_surfaces/${SURFACE_NAME,,}" ]; then
              echo "ERROR: Surface file '$SURFACE_NAME' not found in plasma_surfaces/"
              exit 1
            fi
          fi

      - name: Run case file
        timeout-minutes: 350  # Slightly less than job timeout (360min) to ensure commit step can run
        run: |
          echo "=========================================="
          echo "Running case: ${{ matrix.case_file }}"
          echo "(New case or previously failed - will retry until successful)"
          echo "=========================================="
          stellcoilbench submit-case "${{ matrix.case_file }}"

      - name: Configure Git
        if: always()  # Run even if previous step failed or was canceled
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "$GITHUB_ACTOR"

      - name: Commit submission
        if: always()  # Run even if previous step failed or was canceled
        timeout-minutes: 10  # Quick timeout for commit step
        run: |
          set +e  # Don't exit on error - we'll handle errors explicitly
          CASE_FILE_PATH="${{ matrix.case_file }}"
          
          echo "=========================================="
          echo "Looking for submission for case: $CASE_FILE_PATH"
          echo "Previous step status: ${{ job.status }}"
          echo "=========================================="
          
          # List all zip files found (including any that might have been created before cancellation)
          echo "All zip files in submissions/:"
          find submissions -name "*.zip" -type f 2>/dev/null | sort || echo "No zip files found"
          
          # Also check for any submission directories that might have been created but not zipped yet
          echo "All submission directories (including unzipped):"
          find submissions -type d -mindepth 3 -maxdepth 3 2>/dev/null | sort || echo "No submission directories found"
          
          # Check if there are any unzipped submission directories that should be zipped and committed
          # This handles the case where the case run was canceled but a submission directory was created
          for sub_dir in $(find submissions -type d -mindepth 3 -maxdepth 3 2>/dev/null | sort); do
            if [ ! -f "$sub_dir/all_files.zip" ] && [ -f "$sub_dir/results.json" ]; then
              echo "Found unzipped submission directory: $sub_dir"
              echo "This might be from a canceled run - will attempt to zip and commit if it matches this case"
            fi
          done
          
          # Create Python script to check case match using a heredoc
          # The sed command strips 10 leading spaces to produce valid Python
          # Exit codes: 0 = match, 1 = no match, 2 = error
          sed 's/^          //' > /tmp/check_case_match.py << 'PYTHON_EOF'
          import sys
          import zipfile
          import yaml
          from pathlib import Path
          import os
          
          zip_path = sys.argv[1]
          case_file_path = sys.argv[2]
          
          try:
              with zipfile.ZipFile(zip_path, "r") as zf:
                  if "case.yaml" not in zf.namelist():
                      print(f"  No case.yaml in zip", file=sys.stderr)
                      sys.exit(2)
                  
                  zip_case_content = zf.read("case.yaml").decode("utf-8")
                  zip_case_data = yaml.safe_load(zip_case_content)
                  
                  if zip_case_data is None:
                      print(f"  case.yaml is empty or invalid", file=sys.stderr)
                      sys.exit(2)
                  
                  submission_source = zip_case_data.get("source_case_file", "")
                  if not submission_source:
                      print(f"  No source_case_file in case.yaml", file=sys.stderr)
                      sys.exit(2)
                  
                  repo_root = Path.cwd()
                  
                  try:
                      case_file_abs = (repo_root / case_file_path).resolve()
                      case_file_rel = str(case_file_abs.relative_to(repo_root.resolve()))
                  except ValueError:
                      case_file_rel = case_file_path
                  
                  def normalize_path(p):
                      import re
                      p = re.sub(r'[\\/]+', '/', str(p))
                      p = p.strip("/")
                      return p.lower() if os.name == "nt" else p
                  
                  submission_norm = normalize_path(submission_source)
                  case_file_norm = normalize_path(case_file_rel)
                  
                  submission_filename = Path(submission_source).name
                  case_filename = Path(case_file_path).name
                  
                  print(f"  Submission source_case_file: {submission_source}", file=sys.stderr)
                  print(f"  Submission normalized: {submission_norm}", file=sys.stderr)
                  print(f"  Expected case file: {case_file_rel}", file=sys.stderr)
                  print(f"  Expected normalized: {case_file_norm}", file=sys.stderr)
                  print(f"  Submission filename: {submission_filename}", file=sys.stderr)
                  print(f"  Expected filename: {case_filename}", file=sys.stderr)
                  
                  match_found = False
                  if submission_source == case_file_rel:
                      match_found = True
                      print(f"  Match: exact path match", file=sys.stderr)
                  elif submission_norm == case_file_norm:
                      match_found = True
                      print(f"  Match: normalized path match", file=sys.stderr)
                  elif submission_filename == case_filename:
                      match_found = True
                      print(f"  Match: filename match ({submission_filename})", file=sys.stderr)
                  elif submission_norm.endswith(case_file_norm) or case_file_norm.endswith(submission_norm):
                      match_found = True
                      print(f"  Match: path suffix match", file=sys.stderr)
                  
                  if match_found:
                      print("MATCH")
                      sys.exit(0)
                  else:
                      print(f"  No match (expected {case_file_rel}, got {submission_source})", file=sys.stderr)
                      sys.exit(1)
          except zipfile.BadZipFile:
              print(f"  Invalid zip file", file=sys.stderr)
              sys.exit(2)
          except Exception as e:
              import traceback
              print(f"  Error checking zip: {e}", file=sys.stderr)
              print(f"  Traceback: {traceback.format_exc()}", file=sys.stderr)
              sys.exit(2)
          PYTHON_EOF
          
          # Find zip files and check if they contain case.yaml matching this case
          FOUND_SUBMISSION=false
          MATCHING_ZIP=""
          
          for zip_file in $(find submissions -name "*.zip" -type f 2>/dev/null | sort); do
            echo ""
            echo "Checking zip file: $zip_file"
            # Run Python script and capture both stdout and stderr
            # Exit codes: 0 = match, 1 = no match (continue), 2 = error (log but continue)
            # Use a temporary file to capture output to avoid command substitution issues
            TEMP_OUTPUT=$(mktemp)
            python3 /tmp/check_case_match.py "$zip_file" "$CASE_FILE_PATH" > "$TEMP_OUTPUT" 2>&1
            EXIT_CODE=$?
            MATCH_RESULT=$(cat "$TEMP_OUTPUT")
            rm -f "$TEMP_OUTPUT"
            
            if [ $EXIT_CODE -eq 0 ]; then
              # Match found!
              echo "$MATCH_RESULT" | grep -v "^MATCH$" || true  # Show debug messages
              echo "  ✓ Found matching submission!"
              FOUND_SUBMISSION=true
              MATCHING_ZIP="$zip_file"
              # Export for next step
              echo "FOUND_SUBMISSION=true" >> $GITHUB_ENV
              echo "MATCHING_ZIP=$zip_file" >> $GITHUB_ENV
              break
            elif [ $EXIT_CODE -eq 1 ]; then
              # No match - this is expected, just show the message
              echo "$MATCH_RESULT" | grep -v "^MATCH$" || true
            else
              # Error (exit code 2) - log it but continue checking other files
              echo "  ⚠ Warning: Error checking zip file (exit code $EXIT_CODE):"
              echo "$MATCH_RESULT" | grep -v "^MATCH$" || true
            fi
          done
          
          if [ "$FOUND_SUBMISSION" = "true" ] && [ -n "$MATCHING_ZIP" ]; then
            echo ""
            echo "=========================================="
            echo "Found submission for this case: $MATCHING_ZIP"
            echo "=========================================="
            
            # Add only the submission directory for this specific case
            SUBMISSION_DIR=$(dirname "$MATCHING_ZIP")
            echo "Adding submission directory: $SUBMISSION_DIR"
            
            # Add the entire directory (including zip and PDFs)
            git add "$SUBMISSION_DIR" || echo "Warning: git add failed"
            
            # Also add parent directories if they're new
            git add "$(dirname "$SUBMISSION_DIR")" 2>/dev/null || true
            git add "$(dirname "$(dirname "$SUBMISSION_DIR")")" 2>/dev/null || true
            
            if ! git diff --staged --quiet; then
              echo "Committing submission..."
              if git commit -m "chore: add CI-generated submission for ${{ matrix.case_file }}"; then
                echo "Commit successful"
                echo "Pushing to main..."
                # Retry push up to 3 times in case of conflicts with other parallel jobs
                MAX_RETRIES=3
                RETRY_COUNT=0
                while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
                  if git push origin main; then
                    echo "Push successful"
                    break
                  else
                    RETRY_COUNT=$((RETRY_COUNT + 1))
                    if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                      echo "Push failed (attempt $RETRY_COUNT/$MAX_RETRIES), fetching and retrying..."
                      git fetch origin main
                      # Try to merge remote changes
                      if git merge origin/main --no-edit; then
                        echo "Merged remote changes, retrying push..."
                      else
                        # Resolve conflicts by keeping our submission
                        CONFLICTS=$(git diff --name-only --diff-filter=U 2>/dev/null || true)
                        if [ -n "$CONFLICTS" ]; then
                          echo "$CONFLICTS" | grep "^submissions/" | while read file; do
                            [ -n "$file" ] && git checkout --ours "$file" 2>/dev/null && git add "$file" 2>/dev/null || true
                          done
                          git commit --no-edit || echo "Merge commit failed"
                        fi
                      fi
                    else
                      echo "Warning: Push failed after $MAX_RETRIES attempts (may be a conflict with other parallel jobs)"
                      echo "The submission is committed locally and will be picked up by the commit-submissions job"
                    fi
                  fi
                done
              else
                echo "Warning: Commit failed (submission may already be committed)"
              fi
            else
              echo "No new submissions to commit for this case (already committed or no changes)"
            fi
          else
            echo ""
            echo "=========================================="
            echo "WARNING: No submission found for case $CASE_FILE_PATH"
            echo "=========================================="
            echo "This might indicate:"
            echo "  1. The case failed to generate a submission (check logs above)"
            echo "  2. The submission was generated but not found"
            echo "  3. The case.yaml in the submission doesn't match"
            echo ""
            echo "Checking if submission directory exists:"
            ls -la submissions/*/ 2>/dev/null | head -20 || echo "No submission directories found"
            echo ""
            echo "Checking if case ran successfully (look for errors above)..."
            echo "This job will continue - if the case failed, it will be retried on the next push."
          fi

      - name: Update leaderboard after submission
        if: (success() || failure()) && env.FOUND_SUBMISSION == 'true'
        run: |
          # Update leaderboard with new submission
          echo "=========================================="
          echo "Updating leaderboard with new submission"
          echo "=========================================="
            echo "=========================================="
            echo "Updating leaderboard with new submission"
            echo "=========================================="
            
            # Fetch latest to get any other submissions from parallel jobs
            echo "Fetching latest from origin/main..."
            git fetch origin main || echo "Fetch failed (non-critical)"
            
            # Merge to get all submissions from parallel jobs
            if git rev-parse --verify origin/main > /dev/null 2>&1; then
              BEHIND_COUNT=$(git rev-list origin/main ^HEAD 2>/dev/null | wc -l || echo "0")
              if [ "$BEHIND_COUNT" -gt 0 ]; then
                echo "Merging origin/main to include other submissions from parallel jobs..."
                git merge origin/main --no-edit --no-ff || {
                  CONFLICTS=$(git diff --name-only --diff-filter=U 2>/dev/null || true)
                  if [ -n "$CONFLICTS" ]; then
                    # Resolve conflicts: keep our submissions, accept their docs
                    echo "$CONFLICTS" | grep "^submissions/" | while read file; do
                      [ -n "$file" ] && git checkout --ours "$file" 2>/dev/null && git add "$file" 2>/dev/null || true
                    done
                    echo "$CONFLICTS" | grep "^docs/" | while read file; do
                      [ -n "$file" ] && git checkout --theirs "$file" 2>/dev/null && git add "$file" 2>/dev/null || true
                    done
                    git commit --no-edit || echo "Merge commit failed"
                  else
                    git merge --abort 2>/dev/null || true
                  fi
                }
              fi
            fi
            
            # Remove old leaderboard files to ensure clean regeneration
            echo "Removing old leaderboard files..."
            rm -f docs/leaderboard.json
            if [ -d "docs/leaderboards" ]; then
              find docs/leaderboards -name "*.md" -type f -delete
            fi
            
            # Generate leaderboard files
            echo "Generating leaderboard files..."
            stellcoilbench update-db 2>&1 | tee /tmp/update-db-output.log || echo "update-db completed"
            
            # Add generated leaderboard files
            ADDED_ANY=false
            if [ -f "docs/leaderboard.json" ]; then
              git add docs/leaderboard.json && ADDED_ANY=true
            fi
            if [ -d "docs/leaderboards" ]; then
              find docs/leaderboards -name "*.md" -type f | while read file; do
                git add "$file" && ADDED_ANY=true
              done
            fi
            
            # Commit and push leaderboard updates with retry logic
            if ! git diff --staged --quiet && [ "$ADDED_ANY" = "true" ]; then
              echo "Committing leaderboard updates..."
              if git commit -m "chore: update StellCoilBench leaderboard"; then
                echo "Pushing leaderboard updates..."
                MAX_RETRIES=3
                RETRY_COUNT=0
                while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
                  if git push origin main; then
                    echo "Leaderboard update pushed successfully"
                    break
                  else
                    RETRY_COUNT=$((RETRY_COUNT + 1))
                    if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                      echo "Push failed (attempt $RETRY_COUNT/$MAX_RETRIES), fetching and retrying..."
                      git fetch origin main
                      if git merge origin/main --no-edit; then
                        echo "Merged remote changes, regenerating leaderboard..."
                        # Regenerate after merge
                        rm -f docs/leaderboard.json
                        if [ -d "docs/leaderboards" ]; then
                          find docs/leaderboards -name "*.md" -type f -delete
                        fi
                        stellcoilbench update-db 2>&1 | tee /tmp/update-db-output.log || echo "update-db completed"
                        ADDED_ANY=false
                        if [ -f "docs/leaderboard.json" ]; then
                          git add docs/leaderboard.json && ADDED_ANY=true
                        fi
                        if [ -d "docs/leaderboards" ]; then
                          find docs/leaderboards -name "*.md" -type f | while read file; do
                            git add "$file" && ADDED_ANY=true
                          done
                        fi
                        if ! git diff --staged --quiet && [ "$ADDED_ANY" = "true" ]; then
                          git commit -m "chore: update StellCoilBench leaderboard" || echo "Commit failed"
                        fi
                      else
                        # Resolve conflicts
                        CONFLICTS=$(git diff --name-only --diff-filter=U 2>/dev/null || true)
                        if [ -n "$CONFLICTS" ]; then
                          echo "$CONFLICTS" | grep "^docs/" | while read file; do
                            [ -n "$file" ] && git checkout --ours "$file" 2>/dev/null && git add "$file" 2>/dev/null || true
                          done
                          git commit --no-edit || echo "Merge commit failed"
                        fi
                      fi
                    else
                      echo "Warning: Leaderboard push failed after $MAX_RETRIES attempts"
                    fi
                  fi
                done
              else
                echo "Warning: Leaderboard commit failed"
              fi
            else
              echo "No leaderboard changes to commit"
            fi

  commit-submissions:
    needs: run-cases
    if: always() && needs.run-cases.result != 'skipped'
    runs-on: ubuntu-24.04
    permissions:
      contents: write
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Configure Git
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "$GITHUB_ACTOR"

      - name: Wait for all matrix jobs and fetch submissions
        run: |
          echo "Waiting for all parallel case jobs to complete and commit their submissions..."
          echo "Note: Some jobs may have been canceled or timed out, but we'll collect any submissions that were committed."
          echo "Fetching latest from origin/main to get all submissions from parallel jobs..."
          sleep 30  # Give matrix jobs more time to commit (increased from 10 to 30 seconds)
          git fetch origin main || echo "Fetch failed (non-critical)"
          
          # Show what submissions exist locally vs remotely
          echo ""
          echo "=== Local submissions (before merge) ==="
          find submissions -name "*.zip" -type f 2>/dev/null | wc -l || echo "0"
          echo ""
          echo "=== Remote submissions (after fetch) ==="
          git ls-tree -r --name-only origin/main submissions/ 2>/dev/null | grep "\.zip$" | wc -l || echo "0"
          
          # Merge to get all submissions from parallel jobs
          if git rev-parse --verify origin/main > /dev/null 2>&1; then
            BEHIND_COUNT=$(git rev-list origin/main ^HEAD 2>/dev/null | wc -l || echo "0")
            if [ "$BEHIND_COUNT" -gt 0 ]; then
              echo "Merging origin/main to include all submissions from parallel jobs..."
              git merge origin/main --no-edit --no-ff || {
                CONFLICTS=$(git diff --name-only --diff-filter=U 2>/dev/null || true)
                if [ -n "$CONFLICTS" ]; then
                  echo "$CONFLICTS" | grep "^submissions/" | while read file; do
                    [ -n "$file" ] && git checkout --theirs "$file" 2>/dev/null && git add "$file" 2>/dev/null || true
                  done
                  git commit --no-edit || echo "Merge commit failed"
                else
                  git merge --abort 2>/dev/null || true
                fi
              }
            fi
          fi
          
          echo "All submissions collected:"
          find submissions -name "*.zip" -type f | wc -l || echo "0"

  generate-leaderboard:
    needs: commit-submissions
    if: always() && needs.commit-submissions.result != 'skipped'
    runs-on: ubuntu-24.04
    permissions:
      contents: write
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"

      - name: Install package
        run: |
          pip install -e .

      - name: Configure Git
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "$GITHUB_ACTOR"

      - name: Generate and commit leaderboard files to main
        run: |
          # Ensure we're on main and have latest submissions
          echo "Current branch: $(git branch --show-current)"
          
          # Step 1 already committed submissions locally and pushed them
          # Fetch the latest to ensure we have Step 1's commits
          echo "Fetching latest from origin (including Step 1's commits)..."
          git fetch origin main || echo "Fetch failed (non-critical)"
          
          # Show what commits we have locally vs remote
          echo "Local commits:"
          git log --oneline -5 || echo "No local commits"
          echo "Remote commits:"
          git log --oneline origin/main -5 || echo "No remote commits"
          
          # Clean up any untracked files in docs/leaderboards/ that would conflict with merge
          # These are generated files that will be regenerated anyway - always remove them
          echo "Cleaning untracked files in docs/leaderboards/ that would conflict with merge..."
          # Aggressively remove all untracked files in docs/leaderboards/
          if [ -d "docs/leaderboards" ]; then
            # Remove all untracked .md files
            find docs/leaderboards -name "*.md" -type f ! -path "*/\.git/*" | while read file; do
              if ! git ls-files --error-unmatch "$file" >/dev/null 2>&1; then
                echo "Removing untracked file: $file"
                rm -f "$file"
              fi
            done
            # Also use git clean as fallback
            git clean -fd docs/leaderboards/ 2>/dev/null || true
          fi
          # Also remove untracked leaderboard.json if it exists
          if [ -f "docs/leaderboard.json" ] && ! git ls-files --error-unmatch docs/leaderboard.json >/dev/null 2>&1; then
            echo "Removing untracked file: docs/leaderboard.json"
            rm -f docs/leaderboard.json
          fi
          
          # Step 1 already committed and pushed submissions locally
          # We need to ensure we have those submissions before generating leaderboards
          # Check if we're ahead of origin/main (Step 1's commits)
          LOCAL_COMMITS=$(git rev-list HEAD ^origin/main 2>/dev/null | wc -l || echo "0")
          echo "Local commits ahead of origin/main: $LOCAL_COMMITS"
          
          # If we have local commits, we already have Step 1's submissions
          # Still fetch to get any other remote updates, but don't merge if it would conflict
          echo "Fetching latest from origin..."
          git fetch origin main || echo "Fetch failed (non-critical)"
          
          # Only merge if we're behind origin/main (to get submissions from previous runs)
          # But preserve local commits from Step 1
          if git rev-parse --verify origin/main > /dev/null 2>&1; then
            BEHIND_COUNT=$(git rev-list origin/main ^HEAD 2>/dev/null | wc -l || echo "0")
            if [ "$BEHIND_COUNT" -gt 0 ]; then
              echo "Merging origin/main to include submissions from previous runs..."
              git merge origin/main --no-edit --no-ff || {
                # If merge fails, resolve conflicts by keeping local submissions
                CONFLICTS=$(git diff --name-only --diff-filter=U 2>/dev/null || true)
                if [ -n "$CONFLICTS" ]; then
                  echo "$CONFLICTS" | grep "^submissions/" | while read file; do
                    [ -n "$file" ] && git checkout --ours "$file" 2>/dev/null && git add "$file" 2>/dev/null || true
                  done
                  echo "$CONFLICTS" | grep "^docs/" | while read file; do
                    [ -n "$file" ] && git checkout --theirs "$file" 2>/dev/null && git add "$file" 2>/dev/null || true
                  done
                  git commit --no-edit || echo "Merge commit failed"
                else
                  git merge --abort 2>/dev/null || true
                fi
              }
            else
              echo "Already up to date with origin/main, using local state"
            fi
          fi
          
          # Count submissions (should include both locally committed and merged from remote)
          # Submissions are now zipped
          SUBMISSIONS_COUNT=$(find submissions -name "*.zip" -type f 2>/dev/null | wc -l)
          echo "Submissions found: $SUBMISSIONS_COUNT"
          echo "All submission zip files:"
          find submissions -name "*.zip" -type f | sort || echo "No zip files found"
          
          # Generate leaderboard files (processes all submissions in submissions/ directory)
          # Remove old leaderboard files first to ensure clean regeneration
          echo "Removing old leaderboard files to ensure clean regeneration..."
          rm -f docs/leaderboard.json
          # Remove all existing leaderboard markdown files
          if [ -d "docs/leaderboards" ]; then
            find docs/leaderboards -name "*.md" -type f -delete
            echo "Removed old leaderboard .md files"
          fi
          
          echo "Generating leaderboard files..."
          echo "Running stellcoilbench update-db..."
          # Capture stderr output which contains diagnostics
          stellcoilbench update-db 2>&1 | tee /tmp/update-db-output.log
          echo ""
          echo "=== Update-db diagnostic summary ==="
          grep -E "(Loaded|skipped|filtered|Warning|Methods dict|Leaderboard:|Surface leaderboards|entries|No match|Skipping|score_primary)" /tmp/update-db-output.log | head -50 || echo "No diagnostic output found"
          echo ""
          echo "=== Submissions found ==="
          find submissions -name "*.zip" -type f | sort || echo "No zip files found"
          echo ""
          echo "=== Checking a few submissions for metrics ==="
          # Check first few submissions to see what metrics they have
          printf 'import zipfile\nimport json\nimport sys\nimport os\nzip_file = sys.argv[1]\ntry:\n    with zipfile.ZipFile(zip_file, "r") as zf:\n        if "results.json" in zf.namelist():\n            data = json.loads(zf.read("results.json").decode("utf-8"))\n            metrics = data.get("metrics", {})\n            print(f"  Metrics keys: {list(metrics.keys())[:10]}")\n            print(f"  Has score_primary: {\"score_primary\" in metrics}")\n            print(f"  Has final_normalized_squared_flux: {\"final_normalized_squared_flux\" in metrics}")\n            print(f"  Has final_flux: {\"final_flux\" in metrics}")\n            if "score_primary" in metrics:\n                print(f"  score_primary value: {metrics[\"score_primary\"]}")\n            elif "final_normalized_squared_flux" in metrics:\n                print(f"  final_normalized_squared_flux value: {metrics[\"final_normalized_squared_flux\"]}")\n        else:\n            print("  No results.json in zip")\nexcept Exception as e:\n    print(f"  Error: {e}")\n' > /tmp/check_metrics.py
          for zip_file in $(find submissions -name "*.zip" -type f | head -5); do
            echo ""
            echo "Checking: $zip_file"
            python3 /tmp/check_metrics.py "$zip_file" || echo "  Failed to check"
          done
          echo "===================================="
          
          # Verify all expected leaderboard files were generated
          echo "Verifying generated leaderboard files..."
          if [ -d "docs/leaderboards" ]; then
            echo "Generated leaderboard files:"
            ls -la docs/leaderboards/*.md 2>/dev/null || echo "No .md files found"
            
            # Check for specific surfaces
            for surface in rotating_ellipse LandremanPaul2021_QA circular_tokamak muse_focus; do
              if [ -f "docs/leaderboards/${surface}.md" ]; then
                echo "✓ ${surface}.md exists"
              else
                echo "WARNING: ${surface}.md not found"
              fi
            done
          fi
          
          # Verify files were generated
          echo "Checking generated files..."
          ls -la docs/ 2>/dev/null || echo "docs/ directory not found"
          ls -la docs/*.md 2>/dev/null | head -5 || echo "No markdown files in docs/"
          
          # Add generated leaderboard files
          # Note: docs/leaderboard.json is optional reference, methods.json and cases.json are not saved
          echo "Adding leaderboard files..."
          ADDED_ANY=false
          
          # Add individual files if they exist
          for file in docs/leaderboard.json; do
            if [ -f "$file" ]; then
              echo "Adding $file"
              git add "$file" && ADDED_ANY=true
            else
              echo "File not found: $file"
            fi
          done
          
          # Add leaderboard directories if they exist
          if [ -d "docs/leaderboards" ]; then
            echo "Adding all docs/leaderboards/*.md files"
            # Use find to ensure we get all .md files, including new ones
            find docs/leaderboards -name "*.md" -type f | while read file; do
              echo "  Adding: $file"
              git add "$file" && ADDED_ANY=true
            done
          fi
          
          # Remove old leaderboard file if it exists (singular .md file, replaced by docs/leaderboards/ directory)
          if [ -f "docs/leaderboard.md" ]; then
            echo "Removing old docs/leaderboard.md"
            git rm -f docs/leaderboard.md 2>/dev/null || true
          fi
          # Note: docs/leaderboards/ directory is now tracked, so we don't remove it
          # Files are added/updated explicitly above, and old files will be overwritten by new generation
          
          echo "Files added: $ADDED_ANY"
          
          # Show git status before committing
          echo "Git status before commit:"
          git status --short | head -20
          
          # Commit if there are changes
          if ! git diff --staged --quiet; then
            echo "Committing leaderboard files to main..."
            git commit -m "chore: update StellCoilBench leaderboard" || echo "Commit failed"
            echo "Pushing to main..."
            git push origin main || (echo "ERROR: Failed to push to main" && exit 1)
            echo "Successfully pushed leaderboard files to main"
          else
            echo "No leaderboard changes to commit"
            echo "Staged files:"
            git diff --staged --name-only || echo "No staged files"
            echo "Untracked/modified files:"
            git status --short | grep -E "(docs/|db/)" | head -10 || echo "No leaderboard files found"
          fi

      - name: Trigger ReadTheDocs build
        if: always()
        run: |
          # Trigger ReadTheDocs build via webhook API if credentials are available
          # This ensures docs build happens after CI runs complete and PDFs are committed
          if [ -n "${{ secrets.RTDS_WEBHOOK_URL }}" ] && [ -n "${{ secrets.RTDS_WEBHOOK_TOKEN }}" ]; then
            echo "Triggering ReadTheDocs build..."
            curl -X POST "${{ secrets.RTDS_WEBHOOK_URL }}" \
              -H "Authorization: token ${{ secrets.RTDS_WEBHOOK_TOKEN }}" \
              -H "Content-Type: application/json" \
              -d '{"branches": ["main"]}' || echo "Warning: Failed to trigger ReadTheDocs build (non-critical)"
          else
            echo "ReadTheDocs webhook credentials not configured - skipping build trigger"
            echo "To enable automatic docs builds after CI completes, add RTDS_WEBHOOK_URL and RTDS_WEBHOOK_TOKEN secrets"
            echo "See: https://docs.readthedocs.com/platform/stable/guides/build/webhooks.html"
          fi

