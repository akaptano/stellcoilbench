# .github/workflows/update-db.yml
name: Update StellCoilBench Database

on:
  push:
    branches: [ main ]

jobs:
  determine-cases:
    runs-on: ubuntu-24.04
    outputs:
      cases_to_run_json: ${{ steps.filter.outputs.cases_to_run_json }}
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pyyaml

      - name: Fetch latest submissions from main
        run: |
          git fetch origin main || echo "Fetch failed (non-critical, will check local state)"
          if git rev-parse --verify origin/main > /dev/null 2>&1; then
            BEHIND_COUNT=$(git rev-list origin/main ^HEAD 2>/dev/null | wc -l || echo "0")
            if [ "$BEHIND_COUNT" -gt 0 ]; then
              echo "Merging origin/main to include submissions from previous runs..."
              git merge origin/main --no-edit --no-ff || {
                CONFLICTS=$(git diff --name-only --diff-filter=U 2>/dev/null || true)
                if [ -n "$CONFLICTS" ]; then
                  echo "$CONFLICTS" | grep "^docs/" | while read file; do
                    [ -n "$file" ] && git checkout --theirs "$file" 2>/dev/null && git add "$file" 2>/dev/null || true
                  done
                  echo "$CONFLICTS" | grep "^submissions/" | while read file; do
                    [ -n "$file" ] && git checkout --theirs "$file" 2>/dev/null && git add "$file" 2>/dev/null || true
                  done
                  git commit --no-edit || echo "Merge commit failed"
                else
                  git merge --abort 2>/dev/null || true
                fi
              }
            fi
          fi

      - name: Filter cases to run
        id: filter
        run: |
          ALL_CASE_FILES=$(find cases -name "*.yaml" -type f | sort)
          
          if [ -z "$ALL_CASE_FILES" ]; then
            echo "ERROR: No .yaml files found in cases/ directory!"
            exit 1
          fi
          
          TEMP_CASES=$(mktemp)
          echo "$ALL_CASE_FILES" > "$TEMP_CASES"
          
          PYTHON_OUTPUT=$(python3 - "$TEMP_CASES" << 'PYTHON_SCRIPT'
          import sys
          import yaml
          import zipfile
          from pathlib import Path
          import json
          
          def normalize_yaml_content(content):
              try:
                  data = yaml.safe_load(content)
                  return yaml.dump(data, sort_keys=True, default_flow_style=False)
              except:
                  return content
          
          def case_has_successful_submission(case_file_path):
              case_path = Path(case_file_path)
              if not case_path.exists():
                  return False
              
              try:
                  current_case_content = case_path.read_text()
                  current_case_normalized = normalize_yaml_content(current_case_content)
              except Exception as e:
                  print(f"Warning: Failed to read case file {case_file_path}: {e}", file=sys.stderr)
                  return False
              
              try:
                  repo_root = Path.cwd()
                  case_file_rel = str(case_path.resolve().relative_to(repo_root.resolve()))
              except ValueError:
                  case_file_rel = str(case_path.resolve())
              
              case_file_rel_normalized = case_file_rel.replace("\\", "/")
              
              submissions_dir = Path("submissions")
              if not submissions_dir.exists():
                  return False
              
              zip_files = list(submissions_dir.rglob("*.zip"))
              if len(zip_files) == 0:
                  return False
              
              for zip_path in zip_files:
                  try:
                      with zipfile.ZipFile(zip_path, 'r') as zf:
                          if 'case.yaml' not in zf.namelist() or 'results.json' not in zf.namelist():
                              continue
                          
                          zip_case_content = zf.read('case.yaml').decode('utf-8')
                          zip_case_data = yaml.safe_load(zip_case_content)
                          
                          submission_source = zip_case_data.get('source_case_file', '')
                          if submission_source:
                              submission_source_normalized = submission_source.replace("\\", "/")
                              if (submission_source == case_file_rel or 
                                  submission_source_normalized == case_file_rel_normalized):
                                  zip_case_data_for_comparison = {k: v for k, v in zip_case_data.items() if k != 'source_case_file'}
                                  zip_case_normalized = yaml.dump(zip_case_data_for_comparison, sort_keys=True, default_flow_style=False)
                                  
                                  if zip_case_normalized == current_case_normalized:
                                      return True
                  except Exception as e:
                      print(f"Warning: Failed to process {zip_path}: {e}", file=sys.stderr)
                      continue
              
              return False
          
          if len(sys.argv) > 1:
              with open(sys.argv[1], 'r') as f:
                  case_files = [line.strip() for line in f if line.strip()]
          else:
              case_files = [line.strip() for line in sys.stdin if line.strip()]
          
          if not case_files:
              print("ERROR: No case files found!", file=sys.stderr)
              sys.exit(1)
          
          cases_to_run = []
          cases_already_successful = []
          
          for case_file in case_files:
              if case_has_successful_submission(case_file):
                  cases_already_successful.append(case_file)
                  print(f"SKIP: {case_file} (has successful submission)", file=sys.stderr)
              else:
                  cases_to_run.append(case_file)
                  print(f"RUN: {case_file} (new or no successful submission)", file=sys.stderr)
          
          result = {
              "to_run": cases_to_run,
              "already_successful": cases_already_successful
          }
          print(json.dumps(result))
          PYTHON_SCRIPT
          )
          
          rm -f "$TEMP_CASES"
          
          CASES_TO_RUN_JSON=$(echo "$PYTHON_OUTPUT" | python3 -c "import sys, json; data = json.load(sys.stdin); print(json.dumps(data['to_run']))")
          
          echo "cases_to_run_json<<EOF" >> $GITHUB_OUTPUT
          echo "$CASES_TO_RUN_JSON" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          CASES_TO_RUN=$(echo "$PYTHON_OUTPUT" | python3 -c "import sys, json; data = json.load(sys.stdin); print(' '.join(data['to_run']))")
          echo "Cases to run: $CASES_TO_RUN"
          
          # Also output as a simple string for debugging
          echo "cases_to_run=$CASES_TO_RUN" >> $GITHUB_OUTPUT

  setup-stellcoilbench:
    runs-on: ubuntu-24.04
    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"

      - name: Cache pip packages and wheels
        id: cache-pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-python-3.13-deps-${{ hashFiles('**/pyproject.toml') }}
          restore-keys: |
            pip-${{ runner.os }}-python-3.13-deps-
            pip-${{ runner.os }}-python-3.13-

      - name: Cache VMEC2000 repository
        id: cache-vmec-repo
        uses: actions/cache@v4
        with:
          path: VMEC2000
          key: vmec2000-repo-${{ runner.os }}
          restore-keys: |
            vmec2000-repo-${{ runner.os }}-

      - name: Cache VMEC pip installation
        id: cache-vmec-install
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pip/wheels
            ~/.local/lib/python3.13/site-packages/vmec*
            ${{ env.pythonLocation }}/lib/python3.13/site-packages/vmec*
          key: vmec-install-${{ runner.os }}-python-3.13
          restore-keys: |
            vmec-install-${{ runner.os }}-python-3.13-

      - name: Cache booz_xform pip installation
        id: cache-booz-xform-install
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pip/wheels
            ~/.local/lib/python3.13/site-packages/booz_xform*
            ~/.local/lib/python3.13/site-packages/*booz*
            ${{ env.pythonLocation }}/lib/python3.13/site-packages/booz_xform*
            ${{ env.pythonLocation }}/lib/python3.13/site-packages/*booz*
          key: booz-xform-install-${{ runner.os }}-python-3.13
          restore-keys: |
            booz-xform-install-${{ runner.os }}-python-3.13-

      - name: Cache stellcoilbench installation
        id: cache-stellcoilbench-install
        uses: actions/cache@v4
        with:
          path: |
            ~/.local/lib/python3.13/site-packages/stellcoilbench.egg-info
            ~/.local/lib/python3.13/site-packages/stellcoilbench.egg-link
            ${{ env.pythonLocation }}/lib/python3.13/site-packages/stellcoilbench.egg-info
            ${{ env.pythonLocation }}/lib/python3.13/site-packages/stellcoilbench.egg-link
          key: stellcoilbench-install-${{ runner.os }}-python-3.13-${{ hashFiles('**/pyproject.toml', '**/src/**/*.py') }}
          restore-keys: |
            stellcoilbench-install-${{ runner.os }}-python-3.13-

      - name: apt-get stuff needed for vmec
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential gfortran openmpi-bin libopenmpi-dev libnetcdf-dev libnetcdff-dev liblapack-dev libscalapack-mpi-dev libhdf5-dev libhdf5-serial-dev git m4 libfftw3-dev libboost-all-dev libopenblas-dev graphviz graphviz-dev

      - name: Install python dependencies (setup-stellcoilbench installs these once for all jobs)
        run: |
          python -m pip install --upgrade pip
          # Install all dependencies - pip will use cached wheels if available
          # These are cached in ~/.cache/pip and shared across all parallel jobs
          pip install numpy cmake scikit-build f90nml ninja wheel setuptools pyevtk matplotlib mpi4py h5py f90wrap

      - name: Download the VMEC2000 standalone repository (if not cached)
        if: steps.cache-vmec-repo.outputs.cache-hit != 'true'
        run: git clone --depth=1 https://github.com/hiddensymmetries/VMEC2000.git

      - name: Add to LD_LIBRARY_PATH so scalapack etc can be found
        run: echo "LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu" >> $GITHUB_ENV

      - name: Install booz_xform (if not cached)
        if: steps.cache-booz-xform-install.outputs.cache-hit != 'true'
        run: pip install -v git+https://github.com/hiddenSymmetries/booz_xform

      - name: Verify booz_xform installation
        run: python -c "import booz_xform; print('booz_xform module imported successfully')"

      - name: Configure and install VMEC2000 module (if not cached)
        if: steps.cache-vmec-install.outputs.cache-hit != 'true'
        run: |
          cd VMEC2000
          cp cmake/machines/ubuntu.json cmake_config_file.json
          pip install .

      - name: Verify VMEC installation
        run: python -c "import vmec; print('VMEC module imported successfully')"

      - name: Install stellcoilbench package (setup-stellcoilbench installs this once for all jobs)
        if: steps.cache-stellcoilbench-install.outputs.cache-hit != 'true'
        run: |
          pip install -e .
          python -c "import stellcoilbench; print('stellcoilbench package installed successfully')"

      - name: Verify stellcoilbench installation
        run: |
          python -c "import stellcoilbench; print('stellcoilbench module imported successfully')"
          stellcoilbench --help | head -5 || echo "stellcoilbench CLI available"

  run-cases:
    needs: [determine-cases, setup-stellcoilbench]
    if: needs.determine-cases.outputs.cases_to_run_json != '[]'
    runs-on: ubuntu-24.04
    permissions:
      contents: write
    strategy:
      fail-fast: false
      matrix:
        case_file: ${{ fromJson(needs.determine-cases.outputs.cases_to_run_json) }}
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Fetch all history for proper branch operations
          token: ${{ secrets.GITHUB_TOKEN }}  # Explicit token for write access

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"

      - name: Cache pip packages and wheels (restore from setup-stellcoilbench)
        id: cache-pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-python-3.13-deps-${{ hashFiles('**/pyproject.toml') }}
          restore-keys: |
            pip-${{ runner.os }}-python-3.13-deps-
            pip-${{ runner.os }}-python-3.13-

      - name: Cache VMEC2000 repository
        id: cache-vmec-repo
        uses: actions/cache@v4
        with:
          path: VMEC2000
          key: vmec2000-repo-${{ runner.os }}
          restore-keys: |
            vmec2000-repo-${{ runner.os }}-

      - name: Cache VMEC pip installation
        id: cache-vmec-install
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pip/wheels
            ~/.local/lib/python3.13/site-packages/vmec*
            ${{ env.pythonLocation }}/lib/python3.13/site-packages/vmec*
          key: vmec-install-${{ runner.os }}-python-3.13
          restore-keys: |
            vmec-install-${{ runner.os }}-python-3.13-

      - name: Cache booz_xform pip installation
        id: cache-booz-xform-install
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pip/wheels
            ~/.local/lib/python3.13/site-packages/booz_xform*
            ~/.local/lib/python3.13/site-packages/*booz*
            ${{ env.pythonLocation }}/lib/python3.13/site-packages/booz_xform*
            ${{ env.pythonLocation }}/lib/python3.13/site-packages/*booz*
          key: booz-xform-install-${{ runner.os }}-python-3.13
          restore-keys: |
            booz-xform-install-${{ runner.os }}-python-3.13-

      - name: Cache stellcoilbench installation
        id: cache-stellcoilbench-install
        uses: actions/cache@v4
        with:
          path: |
            ~/.local/lib/python3.13/site-packages/stellcoilbench.egg-info
            ~/.local/lib/python3.13/site-packages/stellcoilbench.egg-link
            ${{ env.pythonLocation }}/lib/python3.13/site-packages/stellcoilbench.egg-info
            ${{ env.pythonLocation }}/lib/python3.13/site-packages/stellcoilbench.egg-link
          key: stellcoilbench-install-${{ runner.os }}-python-3.13-${{ hashFiles('**/pyproject.toml', '**/src/**/*.py') }}
          restore-keys: |
            stellcoilbench-install-${{ runner.os }}-python-3.13-

      - name: Install system dependencies (needed for cached booz_xform and VMEC)
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential gfortran openmpi-bin libopenmpi-dev libnetcdf-dev libnetcdff-dev liblapack-dev libscalapack-mpi-dev libhdf5-dev libhdf5-serial-dev git m4 libfftw3-dev libboost-all-dev libopenblas-dev graphviz graphviz-dev

      - name: Install python dependencies (using cached wheels from setup-stellcoilbench)
        run: |
          python -m pip install --upgrade pip
          # Install dependencies - pip will use cached wheels from setup-stellcoilbench job
          # This is much faster than downloading/building from scratch
          pip install numpy cmake scikit-build f90nml ninja wheel setuptools pyevtk matplotlib mpi4py h5py f90wrap

      - name: Restore VMEC2000 repository from cache (setup-stellcoilbench job already cloned it)
        if: steps.cache-vmec-repo.outputs.cache-hit == 'true'
        run: |
          echo "VMEC2000 repository restored from cache"

      - name: Download the VMEC2000 standalone repository (fallback - should not be needed)
        if: steps.cache-vmec-repo.outputs.cache-hit != 'true'
        run: |
          echo "WARNING: VMEC2000 cache miss - cloning (this should be rare)"
          git clone --depth=1 https://github.com/hiddensymmetries/VMEC2000.git

      - name: Add to LD_LIBRARY_PATH so scalapack etc can be found
        run: echo "LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu" >> $GITHUB_ENV

      - name: Restore booz_xform from cache (setup-stellcoilbench job already installed it)
        if: steps.cache-booz-xform-install.outputs.cache-hit == 'true'
        run: |
          echo "booz_xform installation restored from cache (installed by setup-stellcoilbench job)"
          python -c "import booz_xform; print('booz_xform module imported successfully')"

      - name: Install booz_xform (fallback - should not be needed)
        if: steps.cache-booz-xform-install.outputs.cache-hit != 'true'
        run: |
          echo "WARNING: booz_xform cache miss - installing (this should be rare)"
          pip install -v git+https://github.com/hiddenSymmetries/booz_xform

      - name: Restore VMEC from cache (setup-stellcoilbench job already built it)
        if: steps.cache-vmec-install.outputs.cache-hit == 'true'
        run: |
          echo "VMEC installation restored from cache (built by setup-stellcoilbench job)"
          python -c "import vmec; print('VMEC module imported successfully')"

      - name: Configure and install VMEC2000 module (fallback - should not be needed)
        if: steps.cache-vmec-install.outputs.cache-hit != 'true'
        run: |
          echo "WARNING: VMEC cache miss - installing VMEC (this should be rare)"
          cd VMEC2000
          cp cmake/machines/ubuntu.json cmake_config_file.json
          pip install .
          python -c "import vmec; print('VMEC module imported successfully')"

      - name: Restore stellcoilbench from cache (setup-stellcoilbench job already installed it)
        if: steps.cache-stellcoilbench-install.outputs.cache-hit == 'true'
        run: |
          echo "stellcoilbench installation metadata restored from cache"
          # For editable installs, we still need to run pip install -e . to create the link
          # But pip will use cached .egg-info metadata, making it very fast
          pip install -e . --no-deps || pip install -e .
          python -c "import stellcoilbench; print('stellcoilbench module imported successfully')"

      - name: Install stellcoilbench package (fallback - should not be needed)
        if: steps.cache-stellcoilbench-install.outputs.cache-hit != 'true'
        run: |
          echo "WARNING: stellcoilbench cache miss - installing (this should be rare)"
          pip install -e .
          python -c "import stellcoilbench; print('stellcoilbench package installed successfully')"

      - name: Check if surface file exists
        run: |
          SURFACE_NAME=$(grep -A 2 "surface_params:" "${{ matrix.case_file }}" | grep "surface:" | awk '{print $2}' | tr -d '"')
          if [ -n "$SURFACE_NAME" ]; then
            if [ ! -f "plasma_surfaces/$SURFACE_NAME" ] && [ ! -f "plasma_surfaces/${SURFACE_NAME,,}" ]; then
              echo "ERROR: Surface file '$SURFACE_NAME' not found in plasma_surfaces/"
              exit 1
            fi
          fi

      - name: Run case file
        run: |
          echo "=========================================="
          echo "Running case: ${{ matrix.case_file }}"
          echo "(New case or previously failed - will retry until successful)"
          echo "=========================================="
          stellcoilbench submit-case "${{ matrix.case_file }}"

      - name: Configure Git
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "$GITHUB_ACTOR"

      - name: Commit submission
        run: |
          CASE_FILE_PATH="${{ matrix.case_file }}"
          
          echo "=========================================="
          echo "Looking for submission for case: $CASE_FILE_PATH"
          echo "=========================================="
          
          # List all zip files found
          echo "All zip files in submissions/:"
          find submissions -name "*.zip" -type f 2>/dev/null | sort || echo "No zip files found"
          
          # Create Python script to check case match (using printf to avoid YAML indentation issues)
          printf 'import sys\nimport zipfile\nimport yaml\nfrom pathlib import Path\n\nzip_path = sys.argv[1]\ncase_file_path = sys.argv[2]\n\ntry:\n    with zipfile.ZipFile(zip_path, "r") as zf:\n        if "case.yaml" not in zf.namelist():\n            print(f"  No case.yaml in zip", file=sys.stderr)\n            sys.exit(1)\n        \n        zip_case_content = zf.read("case.yaml").decode("utf-8")\n        zip_case_data = yaml.safe_load(zip_case_content)\n        \n        submission_source = zip_case_data.get("source_case_file", "")\n        repo_root = Path.cwd()\n        case_file_abs = (repo_root / case_file_path).resolve()\n        case_file_rel = str(case_file_abs.relative_to(repo_root.resolve()))\n        \n        # Normalize paths for comparison\n        submission_source_norm = submission_source.replace("\\\\", "/")\n        case_file_rel_norm = case_file_rel.replace("\\\\", "/")\n        \n        print(f"  Submission source_case_file: {submission_source}", file=sys.stderr)\n        print(f"  Expected case file: {case_file_rel}", file=sys.stderr)\n        \n        if submission_source == case_file_rel or submission_source_norm == case_file_rel_norm:\n            print("MATCH")\n            sys.exit(0)\n        else:\n            print(f"  No match", file=sys.stderr)\n            sys.exit(1)\nexcept Exception as e:\n    print(f"Error checking zip: {e}", file=sys.stderr)\n    sys.exit(1)\n' > /tmp/check_case_match.py
          
          # Find zip files and check if they contain case.yaml matching this case
          FOUND_SUBMISSION=false
          MATCHING_ZIP=""
          
          for zip_file in $(find submissions -name "*.zip" -type f 2>/dev/null | sort); do
            echo ""
            echo "Checking zip file: $zip_file"
            MATCH_RESULT=$(python3 /tmp/check_case_match.py "$zip_file" "$CASE_FILE_PATH" 2>&1)
            
            if echo "$MATCH_RESULT" | grep -q "^MATCH$"; then
              echo "  ✓ Found matching submission!"
              FOUND_SUBMISSION=true
              MATCHING_ZIP="$zip_file"
              break
            fi
          done
          
          if [ "$FOUND_SUBMISSION" = "true" ] && [ -n "$MATCHING_ZIP" ]; then
            echo ""
            echo "=========================================="
            echo "Found submission for this case: $MATCHING_ZIP"
            echo "=========================================="
            
            # Add only the submission directory for this specific case
            SUBMISSION_DIR=$(dirname "$MATCHING_ZIP")
            echo "Adding submission directory: $SUBMISSION_DIR"
            
            # Add the entire directory (including zip and PDFs)
            git add "$SUBMISSION_DIR" || echo "Warning: git add failed"
            
            # Also add parent directories if they're new
            git add "$(dirname "$SUBMISSION_DIR")" 2>/dev/null || true
            git add "$(dirname "$(dirname "$SUBMISSION_DIR")")" 2>/dev/null || true
            
            if ! git diff --staged --quiet; then
              echo "Committing submission..."
              if git commit -m "chore: add CI-generated submission for ${{ matrix.case_file }}"; then
                echo "Commit successful"
                echo "Pushing to main..."
                # Retry push up to 3 times in case of conflicts with other parallel jobs
                MAX_RETRIES=3
                RETRY_COUNT=0
                while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
                  if git push origin main; then
                    echo "Push successful"
                    break
                  else
                    RETRY_COUNT=$((RETRY_COUNT + 1))
                    if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                      echo "Push failed (attempt $RETRY_COUNT/$MAX_RETRIES), fetching and retrying..."
                      git fetch origin main
                      # Try to merge remote changes
                      if git merge origin/main --no-edit; then
                        echo "Merged remote changes, retrying push..."
                      else
                        # Resolve conflicts by keeping our submission
                        CONFLICTS=$(git diff --name-only --diff-filter=U 2>/dev/null || true)
                        if [ -n "$CONFLICTS" ]; then
                          echo "$CONFLICTS" | grep "^submissions/" | while read file; do
                            [ -n "$file" ] && git checkout --ours "$file" 2>/dev/null && git add "$file" 2>/dev/null || true
                          done
                          git commit --no-edit || echo "Merge commit failed"
                        fi
                      fi
                    else
                      echo "Warning: Push failed after $MAX_RETRIES attempts (may be a conflict with other parallel jobs)"
                      echo "The submission is committed locally and will be picked up by the commit-submissions job"
                    fi
                  fi
                done
              else
                echo "Warning: Commit failed (submission may already be committed)"
              fi
            else
              echo "No new submissions to commit for this case (already committed or no changes)"
            fi
          else
            echo ""
            echo "=========================================="
            echo "WARNING: No submission found for case $CASE_FILE_PATH"
            echo "=========================================="
            echo "This might indicate:"
            echo "  1. The case failed to generate a submission (check logs above)"
            echo "  2. The submission was generated but not found"
            echo "  3. The case.yaml in the submission doesn't match"
            echo ""
            echo "Checking if submission directory exists:"
            ls -la submissions/*/ 2>/dev/null | head -20 || echo "No submission directories found"
            echo ""
            echo "Checking if case ran successfully (look for errors above)..."
            echo "This job will continue - if the case failed, it will be retried on the next push."
          fi

  commit-submissions:
    needs: run-cases
    if: always() && needs.run-cases.result != 'skipped'
    runs-on: ubuntu-24.04
    permissions:
      contents: write
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Configure Git
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "$GITHUB_ACTOR"

      - name: Wait for all matrix jobs and fetch submissions
        run: |
          echo "Waiting for all parallel case jobs to complete and commit their submissions..."
          echo "Fetching latest from origin/main to get all submissions from parallel jobs..."
          sleep 10  # Give matrix jobs time to commit
          git fetch origin main || echo "Fetch failed (non-critical)"
          
          # Merge to get all submissions from parallel jobs
          if git rev-parse --verify origin/main > /dev/null 2>&1; then
            BEHIND_COUNT=$(git rev-list origin/main ^HEAD 2>/dev/null | wc -l || echo "0")
            if [ "$BEHIND_COUNT" -gt 0 ]; then
              echo "Merging origin/main to include all submissions from parallel jobs..."
              git merge origin/main --no-edit --no-ff || {
                CONFLICTS=$(git diff --name-only --diff-filter=U 2>/dev/null || true)
                if [ -n "$CONFLICTS" ]; then
                  echo "$CONFLICTS" | grep "^submissions/" | while read file; do
                    [ -n "$file" ] && git checkout --theirs "$file" 2>/dev/null && git add "$file" 2>/dev/null || true
                  done
                  git commit --no-edit || echo "Merge commit failed"
                else
                  git merge --abort 2>/dev/null || true
                fi
              }
            fi
          fi
          
          echo "All submissions collected:"
          find submissions -name "*.zip" -type f | wc -l || echo "0"

  generate-leaderboard:
    needs: commit-submissions
    if: always() && needs.commit-submissions.result != 'skipped'
    runs-on: ubuntu-24.04
    permissions:
      contents: write
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"

      - name: Install package
        run: |
          pip install -e .

      - name: Configure Git
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "$GITHUB_ACTOR"

      - name: Generate and commit leaderboard files to main
        run: |
          # Ensure we're on main and have latest submissions
          echo "Current branch: $(git branch --show-current)"
          
          # Step 1 already committed submissions locally and pushed them
          # Fetch the latest to ensure we have Step 1's commits
          echo "Fetching latest from origin (including Step 1's commits)..."
          git fetch origin main || echo "Fetch failed (non-critical)"
          
          # Show what commits we have locally vs remote
          echo "Local commits:"
          git log --oneline -5 || echo "No local commits"
          echo "Remote commits:"
          git log --oneline origin/main -5 || echo "No remote commits"
          
          # Clean up any untracked files in docs/leaderboards/ that would conflict with merge
          # These are generated files that will be regenerated anyway - always remove them
          echo "Cleaning untracked files in docs/leaderboards/ that would conflict with merge..."
          # Aggressively remove all untracked files in docs/leaderboards/
          if [ -d "docs/leaderboards" ]; then
            # Remove all untracked .md files
            find docs/leaderboards -name "*.md" -type f ! -path "*/\.git/*" | while read file; do
              if ! git ls-files --error-unmatch "$file" >/dev/null 2>&1; then
                echo "Removing untracked file: $file"
                rm -f "$file"
              fi
            done
            # Also use git clean as fallback
            git clean -fd docs/leaderboards/ 2>/dev/null || true
          fi
          # Also remove untracked leaderboard.json if it exists
          if [ -f "docs/leaderboard.json" ] && ! git ls-files --error-unmatch docs/leaderboard.json >/dev/null 2>&1; then
            echo "Removing untracked file: docs/leaderboard.json"
            rm -f docs/leaderboard.json
          fi
          
          # Step 1 already committed and pushed submissions locally
          # We need to ensure we have those submissions before generating leaderboards
          # Check if we're ahead of origin/main (Step 1's commits)
          LOCAL_COMMITS=$(git rev-list HEAD ^origin/main 2>/dev/null | wc -l || echo "0")
          echo "Local commits ahead of origin/main: $LOCAL_COMMITS"
          
          # If we have local commits, we already have Step 1's submissions
          # Still fetch to get any other remote updates, but don't merge if it would conflict
          echo "Fetching latest from origin..."
          git fetch origin main || echo "Fetch failed (non-critical)"
          
          # Only merge if we're behind origin/main (to get submissions from previous runs)
          # But preserve local commits from Step 1
          if git rev-parse --verify origin/main > /dev/null 2>&1; then
            BEHIND_COUNT=$(git rev-list origin/main ^HEAD 2>/dev/null | wc -l || echo "0")
            if [ "$BEHIND_COUNT" -gt 0 ]; then
              echo "Merging origin/main to include submissions from previous runs..."
              git merge origin/main --no-edit --no-ff || {
                # If merge fails, resolve conflicts by keeping local submissions
                CONFLICTS=$(git diff --name-only --diff-filter=U 2>/dev/null || true)
                if [ -n "$CONFLICTS" ]; then
                  echo "$CONFLICTS" | grep "^submissions/" | while read file; do
                    [ -n "$file" ] && git checkout --ours "$file" 2>/dev/null && git add "$file" 2>/dev/null || true
                  done
                  echo "$CONFLICTS" | grep "^docs/" | while read file; do
                    [ -n "$file" ] && git checkout --theirs "$file" 2>/dev/null && git add "$file" 2>/dev/null || true
                  done
                  git commit --no-edit || echo "Merge commit failed"
                else
                  git merge --abort 2>/dev/null || true
                fi
              }
            else
              echo "Already up to date with origin/main, using local state"
            fi
          fi
          
          # Count submissions (should include both locally committed and merged from remote)
          # Submissions are now zipped
          SUBMISSIONS_COUNT=$(find submissions -name "*.zip" -type f 2>/dev/null | wc -l)
          echo "Submissions found: $SUBMISSIONS_COUNT"
          echo "All submission zip files:"
          find submissions -name "*.zip" -type f | sort || echo "No zip files found"
          
          # Generate leaderboard files (processes all submissions in submissions/ directory)
          # Remove old leaderboard files first to ensure clean regeneration
          echo "Removing old leaderboard files to ensure clean regeneration..."
          rm -f docs/leaderboard.json
          # Remove all existing leaderboard markdown files
          if [ -d "docs/leaderboards" ]; then
            find docs/leaderboards -name "*.md" -type f -delete
            echo "Removed old leaderboard .md files"
          fi
          
          echo "Generating leaderboard files..."
          echo "Running stellcoilbench update-db..."
          # Capture stderr output which contains diagnostics
          stellcoilbench update-db 2>&1 | tee /tmp/update-db-output.log
          echo ""
          echo "=== Update-db diagnostic summary ==="
          grep -E "(Loaded|skipped|filtered|Warning|Methods dict|Leaderboard:|Surface leaderboards|entries)" /tmp/update-db-output.log | head -20 || echo "No diagnostic output found"
          echo "===================================="
          
          # Verify all expected leaderboard files were generated
          echo "Verifying generated leaderboard files..."
          if [ -d "docs/leaderboards" ]; then
            echo "Generated leaderboard files:"
            ls -la docs/leaderboards/*.md 2>/dev/null || echo "No .md files found"
            
            # Check for specific surfaces
            for surface in rotating_ellipse LandremanPaul2021_QA circular_tokamak muse_focus; do
              if [ -f "docs/leaderboards/${surface}.md" ]; then
                echo "✓ ${surface}.md exists"
              else
                echo "WARNING: ${surface}.md not found"
              fi
            done
          fi
          
          # Verify files were generated
          echo "Checking generated files..."
          ls -la docs/ 2>/dev/null || echo "docs/ directory not found"
          ls -la docs/*.md 2>/dev/null | head -5 || echo "No markdown files in docs/"
          
          # Add generated leaderboard files
          # Note: docs/leaderboard.json is optional reference, methods.json and cases.json are not saved
          echo "Adding leaderboard files..."
          ADDED_ANY=false
          
          # Add individual files if they exist
          for file in docs/leaderboard.json; do
            if [ -f "$file" ]; then
              echo "Adding $file"
              git add "$file" && ADDED_ANY=true
            else
              echo "File not found: $file"
            fi
          done
          
          # Add leaderboard directories if they exist
          if [ -d "docs/leaderboards" ]; then
            echo "Adding all docs/leaderboards/*.md files"
            # Use find to ensure we get all .md files, including new ones
            find docs/leaderboards -name "*.md" -type f | while read file; do
              echo "  Adding: $file"
              git add "$file" && ADDED_ANY=true
            done
          fi
          
          # Remove old leaderboard file if it exists (singular .md file, replaced by docs/leaderboards/ directory)
          if [ -f "docs/leaderboard.md" ]; then
            echo "Removing old docs/leaderboard.md"
            git rm -f docs/leaderboard.md 2>/dev/null || true
          fi
          # Note: docs/leaderboards/ directory is now tracked, so we don't remove it
          # Files are added/updated explicitly above, and old files will be overwritten by new generation
          
          echo "Files added: $ADDED_ANY"
          
          # Show git status before committing
          echo "Git status before commit:"
          git status --short | head -20
          
          # Commit if there are changes
          if ! git diff --staged --quiet; then
            echo "Committing leaderboard files to main..."
            git commit -m "chore: update StellCoilBench leaderboard" || echo "Commit failed"
            echo "Pushing to main..."
            git push origin main || (echo "ERROR: Failed to push to main" && exit 1)
            echo "Successfully pushed leaderboard files to main"
          else
            echo "No leaderboard changes to commit"
            echo "Staged files:"
            git diff --staged --name-only || echo "No staged files"
            echo "Untracked/modified files:"
            git status --short | grep -E "(docs/|db/)" | head -10 || echo "No leaderboard files found"
          fi

      - name: Trigger ReadTheDocs build
        if: always()
        run: |
          # Trigger ReadTheDocs build via webhook API if credentials are available
          # This ensures docs build happens after CI runs complete and PDFs are committed
          if [ -n "${{ secrets.RTDS_WEBHOOK_URL }}" ] && [ -n "${{ secrets.RTDS_WEBHOOK_TOKEN }}" ]; then
            echo "Triggering ReadTheDocs build..."
            curl -X POST "${{ secrets.RTDS_WEBHOOK_URL }}" \
              -H "Authorization: token ${{ secrets.RTDS_WEBHOOK_TOKEN }}" \
              -H "Content-Type: application/json" \
              -d '{"branches": ["main"]}' || echo "Warning: Failed to trigger ReadTheDocs build (non-critical)"
          else
            echo "ReadTheDocs webhook credentials not configured - skipping build trigger"
            echo "To enable automatic docs builds after CI completes, add RTDS_WEBHOOK_URL and RTDS_WEBHOOK_TOKEN secrets"
            echo "See: https://docs.readthedocs.com/platform/stable/guides/build/webhooks.html"
          fi

