Overview
========

StellCoilBench is an open-source benchmark suite for stellarator coil optimization algorithms.
It provides a standardized framework for comparing optimization methods across different plasma
surfaces, ensuring consistent evaluation and reproducible results.

What is StellCoilBench?
------------------------

StellCoilBench addresses a critical need in the stellarator fusion community: **standardized
benchmarking of coil optimization algorithms**. Different research groups use different plasma
surfaces, objective functions, and evaluation metrics, making it difficult to compare methods
fairly. StellCoilBench solves this by:

- **Standardized Case Definitions**: Each benchmark case is defined in a YAML file that
  specifies the plasma surface, coil parameters, optimization settings, and objective terms.

- **Consistent Evaluation**: All submissions are evaluated using the same metrics, ensuring
  fair comparison across different optimization methods.

- **Automated Leaderboards**: CI automatically runs cases, evaluates submissions, and updates
  leaderboards after each successful run.

- **Reproducible Results**: All submissions include complete metadata, allowing others to
  reproduce and verify results.

Key Concepts
------------

**Cases**
   Case files (``cases/*.yaml``) define the optimization problem. Each case specifies:
   
   - The plasma surface geometry (from VMEC or FOCUS input files)
   - Coil configuration (number of coils, Fourier order)
   - Optimization algorithm and parameters
   - Objective function terms (flux error, curvature penalties, etc.)

**Submissions**
   Submissions are the output of running a case. Each submission includes:
   
   - Optimized coil geometry (as JSON)
   - Evaluation metrics (flux error, curvature, forces, etc.)
   - Case metadata (for reproducibility)
   - Visualization outputs (VTK files, PDF plots)

**Leaderboards**
   Leaderboards rank submissions by their primary score (normalized squared flux error).
   Separate leaderboards are maintained for each plasma surface, allowing method comparison
   on specific configurations.

Quick Start
-----------

**Fastest way to get a run:** Add a new case under ``cases/`` and ``git push``. CI will
automatically run the case and update the leaderboards.

To run locally instead:

.. code-block:: bash

   stellcoilbench submit-case cases/my_case.yaml

This creates a submission directory under ``submissions/<surface>/<user>/<timestamp>/``,
zips it into ``submissions/<surface>/<user>/<timestamp>.zip``, and generates PDF plots
next to the zip file for quick inspection.

Repository Layout
------------------

The StellCoilBench repository is organized as follows:

- **``cases/``**: Benchmark case definitions (YAML files)
  
  Each case file defines a complete optimization problem. See :doc:`cases` for details.

- **``submissions/``**: Submission results (organized by surface and user)
  
  Structure: ``submissions/<surface>/<user>/<timestamp>.zip``
  
  Each zip contains:
  
  - ``results.json``: Metrics and metadata
  - ``case.yaml``: The case configuration used
  - ``coils.json``: Optimized coil geometry
  - ``biot_savart_optimized.json``: Biot-Savart field data
  - ``*.vtu``, ``*.vts``: Visualization outputs
  
  PDF plots (e.g., B_N error visualization) are stored **next to** the zip file.

- **``docs/``**: Generated documentation and leaderboards
  
  - ``leaderboard.rst``: Main leaderboard (regenerated by CI)
  - ``leaderboard.json``: Machine-readable leaderboard data
  - ``leaderboards/``: Per-surface markdown leaderboards

- **``plasma_surfaces/``**: Input files for plasma surfaces
  
  Supports VMEC (``input.*``) and FOCUS (``*.focus``) formats.

- **``src/stellcoilbench/``**: Python package source code
  
  - ``cli.py``: Command-line interface
  - ``coil_optimization.py``: Core optimization logic
  - ``evaluate.py``: Case loading and evaluation
  - ``update_db.py``: Leaderboard generation
  - ``validate_config.py``: Case configuration validation

What Happens on Submit
-----------------------

When you run ``stellcoilbench submit-case cases/my_case.yaml``, the following steps occur:

1. **Case Loading**: The case YAML file is loaded and validated.

2. **Surface Loading**: The plasma surface is loaded from ``plasma_surfaces/`` based on the
   case configuration.

3. **Coil Initialization**: Initial coils are created using equally-spaced curves around the
   plasma surface.

4. **Optimization**: The coil optimization loop runs:
   
   - Builds the objective function from case-defined terms
   - Runs the specified optimization algorithm (L-BFGS-B, augmented Lagrangian, etc.)
   - Monitors convergence and applies regularization as needed

5. **Evaluation**: Metrics are computed:
   
   - Normalized squared flux error (primary score)
   - :math:`B_N/|B|` error on the surface
   - Coil geometry metrics (curvature, length, separations)
   - Force and torque metrics
   - Linking number

6. **Output Generation**:
   
   - Writes ``results.json`` with all metrics
   - Saves optimized coil geometry to ``coils.json``
   - Generates VTK visualization files
   - Creates PDF plots of B_N error (initial and optimized)
   - Writes ``case.yaml`` with metadata

7. **Submission Packaging**: The submission directory is zipped, and PDF plots are moved
   next to the zip file.

CI Workflow
-----------

StellCoilBench uses a CI-driven workflow for automated benchmarking:

1. **Case Addition**: When you add a new case file to ``cases/`` and push, CI detects it.

2. **Case Execution**: CI runs the case using ``stellcoilbench submit-case``.

3. **Leaderboard Update**: After successful runs, CI:
   
   - Scans ``submissions/`` for all zip files
   - Loads results and computes rankings
   - Regenerates ``docs/leaderboard.json`` and ``docs/leaderboard.rst``
   - Updates per-surface leaderboards in ``docs/leaderboards/``

4. **Documentation Build**: ReadTheDocs automatically builds and publishes the updated
   documentation, including the latest leaderboards.

This workflow ensures that leaderboards are always up-to-date and that all submissions
are evaluated consistently.

Key Features
------------

**Comprehensive Metrics**
   StellCoilBench evaluates submissions using a wide range of metrics:
   
   - **Primary Score**: Normalized squared flux error (lower is better)
   - **Field Quality**: :math:`B_N/|B|` error (average and maximum)
   - **Coil Geometry**: Curvature, length, coil-to-coil and coil-to-surface distances
   - **Engineering Feasibility**: Forces, torques, linking numbers
   - **Performance**: Optimization time

**Flexible Objective Functions**
   Cases can specify various objective terms:
   
   - Flux error (always included)
   - Total coil length (L2 or thresholded)
   - Coil-to-coil distance (L1/L2 or thresholded)
   - Coil-to-surface distance (L1/L2 or thresholded)
   - Curvature penalties (Lp norm or thresholded)
   - Mean squared curvature (L1/L2 or thresholded)
   - Arclength variation (L2 thresholded)
   - Linking number
   - Coil forces and torques (Lp norm or thresholded)

**Multiple Optimization Algorithms**
   Supports various optimization algorithms from ``scipy.optimize``:
   
   - L-BFGS-B (quasi-Newton method with bounds)
   - Augmented Lagrangian method
   - Other algorithms supported by ``scipy.optimize.minimize``

**High-Quality Visualizations**
   Generates publication-quality PDF plots:
   
   - 3D visualization of B_N error on plasma surface
   - Coils colored by current magnitude
   - Separate plots for initial and optimized coils
   - High-resolution output suitable for papers and presentations

**Reproducibility**
   Every submission includes:
   
   - Complete case configuration
   - Optimized coil geometry
   - All evaluation metrics
   - Hardware and software metadata
   - Timestamp and user information

This ensures that results can be verified and reproduced by others.
