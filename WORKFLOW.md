# StellCoilBench Workflow Guide

## Overview

This repository uses two main directories:

- **`cases/`** - Benchmark case definitions (input)
- **`submissions/`** - Submission results (output, generated)

## Directory Structure

```
stellcoilbench/
├── cases/                    # Benchmark case definitions
│   ├── basic_LandremanPaulQA.yaml
│   ├── basic_MUSE.yaml
│   ├── basic_tokamak.yaml
│   ├── basic_rotating_ellipse.yaml
│   └── README.md
├── submissions/              # Generated submission results
│   ├── LandremanPaul2021_QA/  # Plasma surface name (from case.yaml)
│   │   └── akaptano/         # GitHub username
│   │       └── 11-23-2025_23-03/  # Date and time (MM-DD-YYYY_HH-MM)
│   │           ├── results.json  # Generated by submit-case command
│   │           ├── case.yaml     # Copy of case.yaml used for this submission
│   │           ├── coils.json    # Optimized coil geometry
│   │           ├── biot_savart_optimized.json
│   │           └── *.vtu, *.vts  # VTK visualization files
│   ├── MUSE.focus/           # Different plasma surface
│   │   └── akaptano/
│   │       └── 11-23-2025_23-03/
│   │           └── ...
│   └── README.md
└── docs/                     # Generated leaderboards
    ├── surfaces.md           # Index of all surface leaderboards
    └── surfaces/             # Per-surface leaderboards
        ├── LandremanPaul2021_QA.md
        ├── muse_focus.md
        ├── circular_tokamak.md
        └── rotating_ellipse.md
```

## How to Add a Submission

### Step 1: Define a Case (if needed)

Create or use an existing `case.yaml` file in `cases/`:

```yaml
# cases/my_case.yaml
description: "My optimization test"
surface_params:
  surface: "input.LandremanPaul2021_QA"  # Must match file in plasma_surfaces/
  range: "half period"  # or "full torus"
coils_params:
  ncoils: 4
  order: 4
  verbose: "True"  # or "False"
optimizer_params:
  algorithm: "L-BFGS-B"  # or "BFGS", "SLSQP", "augmented_lagrangian", etc.
  max_iterations: 200
  max_iter_subopt: 10
  verbose: False
  algorithm_options:  # Optional: algorithm-specific hyperparameters
    ftol: 1e-6
    gtol: 1e-5
coil_objective_terms:  # Optional: specify which objectives to include
  total_length: "l2_threshold"
  coil_coil_distance: "l1_threshold"
  coil_surface_distance: "l1_threshold"
  linking_number: ""  # Empty string includes linking number
```

### Step 2: Run and Submit

Run the case to generate a submission:

```bash
stellcoilbench submit-case cases/my_case.yaml
```

**What this does:**
1. Runs the coil optimization for the case
2. Evaluates the results
3. Auto-detects GitHub username from git config (`git config user.name`)
4. Auto-detects hardware (CPU/GPU) from system information
5. Generates `submissions/<surface>/<github_username>/<MM-DD-YYYY_HH-MM>/results.json`
   - Surface name is extracted from `surface_params.surface` in case.yaml
   - Directory structure: `submissions/LandremanPaul2021_QA/akaptano/11-23-2025_23-03/`
6. Saves `coils.json` (optimized coil geometry) in the submission directory
7. Copies `case.yaml` to the submission directory for reference
8. Saves VTK visualization files (*.vtu, *.vts) and `biot_savart_optimized.json` in the submission directory

**Directory naming:**
- Username: Auto-detected from git config (`git config user.name`)
- Timestamp: Current date and time in `MM-DD-YYYY_HH-MM` format (e.g., `12-20-2024_14-30`)

**Submission identification:**
Each submission is uniquely identified by:
- **Date submitted**: Timestamp in directory name (`MM-DD-YYYY_HH-MM`)
- **GitHub username**: Auto-detected from git config
- **Metadata**: All case parameters stored in `case.yaml` (copied to submission directory)

**Optional flags:**
- `--method-name` - Name of your optimization method (optional, stored in metadata)
- `--notes` - Add notes about the submission (optional, stored in metadata)

### Step 3: Commit and Push

Commit the generated submission directory:

```bash
git add submissions/<surface>/<your_username>/<timestamp>/
git commit -m "Add submission"
git push
```

Replace `<surface>`, `<your_username>`, and `<timestamp>` with the actual values from your submission directory.

### Step 4: CI Updates Leaderboard

When you push, CI automatically:
1. Commits your submission
2. Scans `submissions/` for all `results.json` files
3. Generates `docs/leaderboard.json` and per-surface leaderboards in `docs/surfaces/`
4. Commits the leaderboard files (`docs/`)

**Important**: 
- All files (`submissions/` and `docs/`) are committed to the repository
- Leaderboard files (`docs/`) are automatically generated and updated by CI

## How It Works

### `cases/` Directory
- **Purpose**: Defines benchmark cases (problem specifications)
- **Format**: YAML files with case configuration
- **Usage**: Input to `submit-case` command
- **Git**: Tracked in git (part of the benchmark definition)

### `submissions/` Directory  
- **Purpose**: Stores submission results (solution outputs)
- **Format**: `results.json` files organized by surface/username/timestamp
- **Usage**: Scanned by `update-db` to build leaderboard
- **Git**: Tracked in git (submissions are part of the repo)
- **Identification**: Each submission is identified by GitHub username, submission date/time, and metadata in `case.yaml`

### Generated Files (`docs/`)
- **Purpose**: Aggregated database and per-surface leaderboards
- **Format**: JSON (docs/leaderboard.json) and Markdown (docs/surfaces/)
- **Usage**: Displayed on GitHub
- **Git**: Tracked in git
- **Update**: Automatically generated and updated by CI when submissions are pushed

## Example Workflow

```bash
# 1. Create a case (or use existing)
cp cases/case.yaml cases/my_test_case.yaml
# Edit my_test_case.yaml as needed

# 2. Run and submit
stellcoilbench submit-case cases/my_test_case.yaml

# 3. Check the generated submission (directory name will be your username + timestamp)
ls submissions/$(git config user.name)/
cat submissions/$(git config user.name)/*/results.json

# 4. Commit and push
git add submissions/
git commit -m "Add submission"
git push

# 5. CI will update the leaderboard automatically
```

## Key Points

- **Cases** (`cases/`) = Problem definitions (what to optimize)
- **Submissions** (`submissions/`) = Results (your solutions)
- **Leaderboard files** (`docs/`) = Generated per-surface leaderboards and leaderboard.json
- **Put submissions in `submissions/`** - either:
  - Generate them with `submit-case` command (recommended)
  - Or manually create `results.json` files following the format
- **CI scans `submissions/`** to build per-surface leaderboards
- **Each submission** = one `results.json` file in `submissions/<surface>/<username>/<MM-DD-YYYY_HH-MM>/`
- **Leaderboard files are auto-generated** - `docs/` directory is created and updated by CI
- **All files are tracked** - `submissions/` and `docs/` are all committed to the repository

## Viewing the Leaderboard

The leaderboard is automatically updated:
- Browse: `https://github.com/<your-repo>/blob/main/docs/surfaces.md` (index of all surfaces)
- Or browse individual surface leaderboards: `https://github.com/<your-repo>/blob/main/docs/surfaces/<surface>.md`

